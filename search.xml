<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Trinity获取机器码方式</title>
      <link href="/2019/10/08/trinity-huo-qu-ji-qi-ma-fang-shi/"/>
      <url>/2019/10/08/trinity-huo-qu-ji-qi-ma-fang-shi/</url>
      
        <content type="html"><![CDATA[<h3 id="1、使用LicenseCMD-jar获取机器码"><a href="#1、使用LicenseCMD-jar获取机器码" class="headerlink" title="1、使用LicenseCMD.jar获取机器码"></a>1、使用LicenseCMD.jar获取机器码</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将 LicenseCMD.jar 置于 &lt;Trinity&gt;JCSServer/bin 目录下。(标灰处请依实际目录输入)</span></span><br><span class="line"><span class="comment"># 执行指令 java -jar &lt;Trinity&gt;\JCSServer\bin\LicenseCMD.jar -m，即可取得 Machine Code。(标灰处请依实际目录输入)</span></span><br></pre></td></tr></table></figure><h3 id="2、激活License"><a href="#2、激活License" class="headerlink" title="2、激活License"></a>2、激活License</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1、将 License.key 置于 &lt;Trinity&gt;\JCSServer\cfg 目录下。(标灰处请依实际目录输入)</span><br><span class="line">2、使用命令激活key</span><br><span class="line">java -jar   /JCSServer/bin/LicenseCMD.jar -i key目录/key名称</span><br><span class="line">3、输入密码（密码位于passwd.txt文件中）</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注：若 LicenseCMD.jar 逾期，则显示「LicensCMD was expired」警示讯息。</span></span><br></pre></td></tr></table></figure><h3 id="3、检查License内容"><a href="#3、检查License内容" class="headerlink" title="3、检查License内容"></a>3、检查License内容</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1、执行命令，文件位置根据实际情况输入</span><br><span class="line">java -jar &lt;Trinity&gt;/JCSServer/bin/LicenseCMD.jar -s</span><br><span class="line">2、返回信息</span><br><span class="line">待补充</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trinity Linux 安装步骤</title>
      <link href="/2019/10/08/trinity-linux-an-zhuang-bu-zou/"/>
      <url>/2019/10/08/trinity-linux-an-zhuang-bu-zou/</url>
      
        <content type="html"><![CDATA[<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Trinity Version：4.1.1.233</span><br><span class="line">Java Version：JAVA1.8</span><br></pre></td></tr></table></figure><h2 id="一、安装java环境"><a href="#一、安装java环境" class="headerlink" title="一、安装java环境"></a>一、安装java环境</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># root用户</span></span><br><span class="line">1、下载jdk</span><br><span class="line">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</span><br><span class="line">2、解压jdk并安装</span><br><span class="line">tar -xvzf jdk-8u221-linux-x64.tar.gz -C /usr/</span><br><span class="line"><span class="built_in">cd</span> /usr</span><br><span class="line">mv jdk-1.8.0_221 java</span><br><span class="line">3、配置环境变量</span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line">4、生效配置</span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br><span class="line">5、检验Java是否生效</span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><h2 id="二、安装PG（Postgresql）"><a href="#二、安装PG（Postgresql）" class="headerlink" title="二、安装PG（Postgresql）"></a>二、安装PG（Postgresql）</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># root用户下</span></span><br><span class="line">1、运行安装文件</span><br><span class="line">./postgresql-9.5.10-1-linux-x64.run --mode text</span><br><span class="line"></span><br><span class="line">2、选择安装目录</span><br><span class="line">Please specify the directory <span class="built_in">where</span> PostgreSQL will be installed.</span><br><span class="line">Installation Directory [/opt/PostgreSQL/9.5]:(按 Enter 使用预设)</span><br><span class="line"></span><br><span class="line">3、选择数据存储位置</span><br><span class="line">Please select a directory under <span class="built_in">which</span> to store your data.</span><br><span class="line">Data Directory [/opt/PostgreSQL/9.5/data]:(按 Enter 使用预设)</span><br><span class="line"></span><br><span class="line">4、输入数据库的密码</span><br><span class="line">Please provide a password <span class="keyword">for</span> the database superuser (postgres).</span><br><span class="line">Password :trinity</span><br><span class="line">Retype password : trinity</span><br><span class="line"></span><br><span class="line">5、选择端口号</span><br><span class="line">Please select the port number the server should listen on.</span><br><span class="line">Port [5432]: (按 Enter 使用预设)</span><br><span class="line"></span><br><span class="line">6、选择语言</span><br><span class="line">[16] en_US.utf8</span><br><span class="line">Please choose an option [1] :16</span><br><span class="line"></span><br><span class="line">7、确认开始安装</span><br><span class="line">Setup is now ready to begin installing PostgreSQL on your computer.</span><br><span class="line">Do you want to <span class="built_in">continue</span>? [Y/n]:Y</span><br><span class="line"></span><br><span class="line">8、完成安装</span><br><span class="line">Please <span class="built_in">wait</span> <span class="keyword">while</span> Setup installs PostgreSQL on your computer.</span><br><span class="line">Installing</span><br><span class="line">0% ______________ 50% ______________ 100% <span class="comment">#########################################</span></span><br><span class="line">-------------------------------------------------------------------- Setup has finished installing PostgreSQL on your computer.</span><br><span class="line"></span><br><span class="line">9、取消 Launch Stack Builder</span><br><span class="line">Launch Stack Builder at <span class="built_in">exit</span>?</span><br><span class="line">Stack Builder may be used to download and install additional tools, drivers and applications to complement your PostgreSQL installation. [Y/n]:n</span><br></pre></td></tr></table></figure><h2 id="三、初始化Trinity数据库"><a href="#三、初始化Trinity数据库" class="headerlink" title="三、初始化Trinity数据库"></a>三、初始化Trinity数据库</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># root用户</span></span><br><span class="line">su - postgres</span><br><span class="line">/opt/PostgreSQL/9.5/bin/psql -h ip</span><br><span class="line"></span><br><span class="line">1、创建user</span><br><span class="line">CREATE USER trinity WITH PASSWORD <span class="string">'trinity'</span>;</span><br><span class="line">2、创建数据库</span><br><span class="line">CREATE DATABASE trinity OWNER trinity;</span><br><span class="line">3、切换用户测试</span><br><span class="line">/opt/PostgreSQL/9.2/bin/psql -U trinity</span><br></pre></td></tr></table></figure><h2 id="四、执行Trinity安装程序"><a href="#四、执行Trinity安装程序" class="headerlink" title="四、执行Trinity安装程序"></a>四、执行Trinity安装程序</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># trinity用户</span></span><br><span class="line">1、执行安装程序</span><br><span class="line">java -jar TrinityInstaller-v4.1.1.233.jar -console</span><br><span class="line"></span><br><span class="line">2、选择安装的产品</span><br><span class="line">选取需要安装的产品，输入对应的产品号码(默认为全选)，当产品被选取之后，会显示*号，输入 0 进行下一个步骤.。</span><br><span class="line">Trinity Product List:</span><br><span class="line">[*]1. JCS Server</span><br><span class="line">[*]2. JCS Agent</span><br><span class="line">[*]3. DIS Server</span><br><span class="line">[*]4. Trinity Repository</span><br><span class="line">press 0 to next step.</span><br><span class="line">Please select install trinity product:0</span><br><span class="line"></span><br><span class="line">3、输入安装位置</span><br><span class="line">Please input install Product Path(Default: /home/Users/Trinity):</span><br><span class="line"></span><br><span class="line">4、选取所要使用的 IP，这里的范例选择 127.0.0.1。</span><br><span class="line">IP List:</span><br><span class="line">[ ] 1. 192.168.10.129</span><br><span class="line">[ ] 2. 127.0.0.1</span><br><span class="line">Please select IP, press 0 to next step:2</span><br><span class="line"></span><br><span class="line">5、连接PG数据库</span><br><span class="line">Please input PostgreSQL info:</span><br><span class="line">Host(localhost):</span><br><span class="line">Use default: ip</span><br><span class="line">Port(5432):</span><br><span class="line">Use default: 5432</span><br><span class="line">Database Name(trinity):</span><br><span class="line">Use default: trinity</span><br><span class="line">User Name(trinity):</span><br><span class="line">Use default: trinity</span><br><span class="line">password(trinity):</span><br><span class="line">Use default: trinity</span><br><span class="line">Is drop table?[y/n]</span><br><span class="line">Use defeclt: y</span><br><span class="line">UI Server Port[8080]:</span><br><span class="line"></span><br><span class="line">6、进行安装</span><br><span class="line">Install Product:</span><br><span class="line">Trinity JCS Server</span><br><span class="line">Trinity JCS Agent</span><br><span class="line">Trinity DIS Service</span><br><span class="line">Install Path:/home/Users/Trinity</span><br><span class="line">Install IP: 127.0.0.1</span><br><span class="line">Database Host:ip</span><br><span class="line">Database Port:5432</span><br><span class="line">Database Name:trinity</span><br><span class="line">Database User:trinity</span><br><span class="line">Database Password:trinity</span><br><span class="line"></span><br><span class="line">7、取消license激活</span><br><span class="line">Import licence file? [y/n]n</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trinity修改PG数据库密码</title>
      <link href="/2019/10/08/trinity-xiu-gai-pg-shu-ju-ku-mi-ma/"/>
      <url>/2019/10/08/trinity-xiu-gai-pg-shu-ju-ku-mi-ma/</url>
      
        <content type="html"><![CDATA[<h3 id="1、在PG数据库中修改Trinity用户的密码"><a href="#1、在PG数据库中修改Trinity用户的密码" class="headerlink" title="1、在PG数据库中修改Trinity用户的密码"></a>1、在PG数据库中修改Trinity用户的密码</h3><p><img src="https://raw.githubusercontent.com/zhangpotato/blog-image/master/trinity-change-pg-passwd/1.jpg" alt=""></p><h3 id="2、JCSServer-修改-JCSServer-cfg-jcsserver-conf-参数-POSTGRESQL-PASSWORD"><a href="#2、JCSServer-修改-JCSServer-cfg-jcsserver-conf-参数-POSTGRESQL-PASSWORD" class="headerlink" title="2、JCSServer 修改 JCSServer\cfg\jcsserver.conf 参数 POSTGRESQL_PASSWORD"></a>2、JCSServer 修改 JCSServer\cfg\jcsserver.conf 参数 POSTGRESQL_PASSWORD</h3><p><img src="https://raw.githubusercontent.com/zhangpotato/blog-image/master/trinity-change-pg-passwd/2.jpg" alt=""></p><h3 id="3、JCSAgent修改JCSAgent-cfg-jcsagent-conf-参数-POSTGRESQL-PASSWORD"><a href="#3、JCSAgent修改JCSAgent-cfg-jcsagent-conf-参数-POSTGRESQL-PASSWORD" class="headerlink" title="3、JCSAgent修改JCSAgent\cfg\jcsagent.conf 参数 POSTGRESQL_PASSWORD"></a>3、JCSAgent修改JCSAgent\cfg\jcsagent.conf 参数 POSTGRESQL_PASSWORD</h3><p><img src="https://raw.githubusercontent.com/zhangpotato/blog-image/master/trinity-change-pg-passwd/3.jpg" alt=""></p><h3 id="4、DISServer修改DIsServer-cfg-dis-server-properties-参数-DATABASE-PASSWORD"><a href="#4、DISServer修改DIsServer-cfg-dis-server-properties-参数-DATABASE-PASSWORD" class="headerlink" title="4、DISServer修改DIsServer\cfg\dis.server.properties 参数 DATABASE_PASSWORD"></a>4、DISServer修改DIsServer\cfg\dis.server.properties 参数 DATABASE_PASSWORD</h3><p><img src="https://raw.githubusercontent.com/zhangpotato/blog-image/master/trinity-change-pg-passwd/4.jpg" alt=""></p><h3 id="5、修改DISServer-cfg-trinity-properties-参数-database-password"><a href="#5、修改DISServer-cfg-trinity-properties-参数-database-password" class="headerlink" title="5、修改DISServer\cfg\trinity.properties 参数 database.password"></a>5、修改DISServer\cfg\trinity.properties 参数 database.password</h3><p><img src="https://raw.githubusercontent.com/zhangpotato/blog-image/master/trinity-change-pg-passwd/5.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trinity更改服务IP</title>
      <link href="/2019/10/08/trinity-geng-gai-fu-wu-ip/"/>
      <url>/2019/10/08/trinity-geng-gai-fu-wu-ip/</url>
      
        <content type="html"><![CDATA[<p>如要变更 Trinity 相关服务的 IP，请修改下列档案，并依底下范例红字所示，修改参数设定:</p><h3 id="1、Trinity-DISServer-cfg-dis-server-properties"><a href="#1、Trinity-DISServer-cfg-dis-server-properties" class="headerlink" title="1、Trinity/DISServer/cfg/dis.server.properties"></a>1、Trinity/DISServer/cfg/dis.server.properties</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">DIS_SERVER_IP=&lt;欲变更的 IP&gt; </span><br><span class="line">DATABASE_URL=jdbc:postgresql://&lt;欲变更的 IP&gt;:5432/trinity</span><br></pre></td></tr></table></figure><h3 id="2、Trinity-DISServer-cfg-trinity-properties"><a href="#2、Trinity-DISServer-cfg-trinity-properties" class="headerlink" title="2、Trinity/DISServer/cfg/trinity.properties"></a>2、Trinity/DISServer/cfg/trinity.properties</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">database.url= jdbc:postgresql://&lt;欲变更的 IP&gt;:5432/trinity </span><br><span class="line">trinity.server.url= http://&lt;欲变更的 IP&gt;:8080 </span><br><span class="line">trinity.uiap.ip=&lt;欲变更的 IP&gt;</span><br></pre></td></tr></table></figure><h3 id="3、Trinity-JCSAgent-cfg-jcsagent-conf"><a href="#3、Trinity-JCSAgent-cfg-jcsagent-conf" class="headerlink" title="3、Trinity/JCSAgent/cfg/jcsagent.conf"></a>3、Trinity/JCSAgent/cfg/jcsagent.conf</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">JCS_SERVER_IP=&lt;欲变更的 IP&gt;</span><br></pre></td></tr></table></figure><h3 id="4、Trinity-JCSServer-cfg-jcsserver-conf"><a href="#4、Trinity-JCSServer-cfg-jcsserver-conf" class="headerlink" title="4、Trinity/JCSServer/cfg/jcsserver.conf"></a>4、Trinity/JCSServer/cfg/jcsserver.conf</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">JCS_AGENT_IP=&lt;欲变更的 IP&gt;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trinity服务启动及关闭</title>
      <link href="/2019/10/08/trinity-fu-wu-qi-dong-ji-guan-bi/"/>
      <url>/2019/10/08/trinity-fu-wu-qi-dong-ji-guan-bi/</url>
      
        <content type="html"><![CDATA[<h3 id="一、启动Trinity服务"><a href="#一、启动Trinity服务" class="headerlink" title="一、启动Trinity服务"></a>一、启动Trinity服务</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动顺序 JCS Server 服务 -&gt; JCS Agent 服务 -&gt; DIS Server 服务</span></span><br><span class="line">Trinity/JCSServer/bin/startup.sh</span><br><span class="line">Trinity/JCSAgent/bin/startup.sh</span><br><span class="line">Trinity/DISServer/bin/startup.sh</span><br></pre></td></tr></table></figure><h3 id="二、停止Trinity服务"><a href="#二、停止Trinity服务" class="headerlink" title="二、停止Trinity服务"></a>二、停止Trinity服务</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 关闭顺序DIS Server 服务 -&gt; JCS Agent 服务 -&gt; JCS Server 服务</span></span><br><span class="line">Trinity/DISServer/bin/shutdown.sh</span><br><span class="line">Trinity/JCSAgent/bin/shutdown.sh</span><br><span class="line">Trinity/JCSServer/bin/shutdown.sh</span><br></pre></td></tr></table></figure><h3 id="三、检查Trinity服务"><a href="#三、检查Trinity服务" class="headerlink" title="三、检查Trinity服务"></a>三、检查Trinity服务</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">ps -ef|grep jcsserver.jar</span><br><span class="line">ps -ef|grep jcsagent.jar</span><br><span class="line">ps -ef|grep DISServer</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/08/21/pgadmin-wu-fa-lian-jie-trinity-shu-ju-ku/"/>
      <url>/2019/08/21/pgadmin-wu-fa-lian-jie-trinity-shu-ju-ku/</url>
      
        <content type="html"><![CDATA[<h3 id="1、报错信息"><a href="#1、报错信息" class="headerlink" title="1、报错信息"></a>1、报错信息</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">could not connect to server: Connection refused</span><br><span class="line">Is the server running on host host.domain.com and accepting</span><br><span class="line">TCP/IP connections on port 5432?</span><br></pre></td></tr></table></figure><h3 id="2、解决方法"><a href="#2、解决方法" class="headerlink" title="2、解决方法"></a>2、解决方法</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1、添加pg远程访问权限</span><br><span class="line">vim &lt;postgresql 数据目录&gt;\data\pg_hba.conf</span><br><span class="line">2、添加ip</span><br><span class="line"><span class="comment"># 在 TYPE DATABASE USER ADDRESS METHOD 下方添加</span></span><br><span class="line">host all all &lt;IP-address&gt;/&lt;mask-length&gt; md5</span><br><span class="line"></span><br><span class="line">注：IP-address 代表允许连入的 ip, 而 mask-length 代表子网掩码长度，最小值是 0, 最大值是 32。</span><br><span class="line">若要设定全部开放，则可设定为：</span><br><span class="line">host all all 0.0.0.0/0 md5</span><br><span class="line">若要设定允许连入的网址为:192.168.3.* ，则可设定为:</span><br><span class="line">host all all 192.168.3.0/24 md5</span><br><span class="line">3、修改listen_addresses</span><br><span class="line">设置&lt;postgresql 数据目录&gt;\data\postgresql.conf 中的 listen_addresses 与 port 设定与以 下相同:</span><br><span class="line">listen_addresses = <span class="string">'*'</span> </span><br><span class="line">port = 5432 </span><br><span class="line">4、重启pg数据库</span><br><span class="line">pg_ctl start [-w] [-s] [-D datadir] [-l filename] [-o options] [-p path]</span><br><span class="line">pg_ctl stop [-W] [-s] [-D datadir] [-m s[mart] | f[ast] | i[mmediate] ]</span><br><span class="line">pg_ctl restart [-w] [-s] [-D datadir] [-m s[mart] | f[ast] | i[mmediate] ] [-o options]</span><br><span class="line"></span><br><span class="line">pg_ctl restart -D &lt;PG 数据目录位置&gt;/data</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2019/08/02/kafka-ji-ben-cao-zuo/"/>
      <url>/2019/08/02/kafka-ji-ben-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h1 id="Kafka-基本操作"><a href="#Kafka-基本操作" class="headerlink" title="Kafka 基本操作"></a>Kafka 基本操作</h1><h2 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --create --zookeeper host0:2181,host1:2181,host2:2181,host3:2181,host4:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#-replication-factor 1 数据副本数为1</span></span><br><span class="line"><span class="comment">#-partitions 1 分区数量</span></span><br><span class="line"><span class="comment">#--topic test topic name</span></span><br></pre></td></tr></table></figure><h2 id="查看topic"><a href="#查看topic" class="headerlink" title="查看topic"></a>查看topic</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./kafka-topics.sh --list  --zookeeper host0:2181,host1:2181,host2:2181,host3:2181,host4:2181</span><br></pre></td></tr></table></figure><h2 id="生产消息"><a href="#生产消息" class="headerlink" title="生产消息"></a>生产消息</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./kafka-console-producer.sh --broker-list host1:6667,host4:6667,host3:6667,host2:6667 --topic <span class="built_in">test</span></span><br><span class="line"><span class="comment">#--broker-list 为kafka broker所有节点的列表（集群版本）</span></span><br><span class="line"><span class="comment">#host1:6667 为kafka配置中listeners的配置端口号</span></span><br><span class="line"><span class="comment">#--topic test消息发送的topic name</span></span><br></pre></td></tr></table></figure><h2 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">./kafka-console-consumer.sh --zookeeper host0:2181,host1:2181,host2:2181,host3:2181,host4:2181 --topic <span class="built_in">test</span> --from-beginning</span><br></pre></td></tr></table></figure><h2 id="kafka-connect"><a href="#kafka-connect" class="headerlink" title="kafka connect"></a>kafka connect</h2><h2 id="kafka-Stream"><a href="#kafka-Stream" class="headerlink" title="kafka Stream"></a>kafka Stream</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Sqoop基础教程</title>
      <link href="/2019/07/23/sqoop-ji-chu-jiao-cheng/"/>
      <url>/2019/07/23/sqoop-ji-chu-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h1 id="一、Sqoop导入"><a href="#一、Sqoop导入" class="headerlink" title="一、Sqoop导入"></a>一、Sqoop导入</h1><h2 id="1、Sqoop参数使用方式"><a href="#1、Sqoop参数使用方式" class="headerlink" title="1、Sqoop参数使用方式"></a>1、Sqoop参数使用方式</h2><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>codegen</td><td>生成与数据库记录交互的代码</td></tr><tr><td>create-hive-table</td><td>创建表</td></tr><tr><td>eval</td><td>评估SQL语句并显示结果</td></tr><tr><td>export</td><td>将HDFS目录导出到数据库表</td></tr><tr><td>help</td><td>列出可用命令</td></tr><tr><td>import</td><td>数据库中的表导入HDFS</td></tr><tr><td>import-all-tables</td><td>将数据库中的表导入HDFS</td></tr><tr><td>import-mainframe</td><td>将主机数据集导入HDFS</td></tr><tr><td>list-databases</td><td>列出服务器列表中的可用数据库</td></tr><tr><td>list-tables</td><td>列出数据库中可用的表</td></tr></tbody></table><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在命令行中使用参数选项</span></span><br><span class="line">sqoop list-databases --connect jdbc:mysql://host0:3306 --username root --password 123456</span><br><span class="line"><span class="comment">#使用配置文件的方式</span></span><br><span class="line">sqoop --options-file /root/list.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#vim list.txt</span></span><br><span class="line">list-databases</span><br><span class="line">--connect</span><br><span class="line">jdbc:mysql://host0:3306</span><br><span class="line">--username</span><br><span class="line">root</span><br><span class="line">--password</span><br><span class="line">123456</span><br></pre></td></tr></table></figure><h2 id="2、sqoop-import"><a href="#2、sqoop-import" class="headerlink" title="2、sqoop-import"></a>2、sqoop-import</h2><p>目的：将单个表从RDBMS导入HDFS。表中的每一行都表示为HDFS中的单独记录。记录可以存储为文本文件（每行一个记录），或者以二进制表示形式存储为Avro或SequenceFiles。</p><h3 id="A、连接常见参数："><a href="#A、连接常见参数：" class="headerlink" title="A、连接常见参数："></a><strong>A、连接常见参数：</strong></h3><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">–connect <jdbc-uri></jdbc-uri></td><td style="text-align:left">指定JDBC连接字符串</td></tr><tr><td style="text-align:left">–connection-manager <class-name></class-name></td><td style="text-align:left">指定要使用的连接管理器类</td></tr><tr><td style="text-align:left">–driver <class-name></class-name></td><td style="text-align:left">手动指定要使用的JDBC驱动程序类</td></tr><tr><td style="text-align:left">–hadoop-mapred-home <dir></dir></td><td style="text-align:left">覆盖$ HADOOP_MAPRED_HOME</td></tr><tr><td style="text-align:left">–password-file</td><td style="text-align:left">设置包含验证密码的文件的路径</td></tr><tr><td style="text-align:left">-P</td><td style="text-align:left">从控制台读取密码</td></tr><tr><td style="text-align:left">–password <password></password></td><td style="text-align:left">设置验证密码</td></tr><tr><td style="text-align:left">–username <username></username></td><td style="text-align:left">设置认证用户名</td></tr><tr><td style="text-align:left">–verbose</td><td style="text-align:left">工作时打印更多信息</td></tr><tr><td style="text-align:left">–connection-param-file <filename></filename></td><td style="text-align:left">提供连接参数的可选属性文件</td></tr><tr><td style="text-align:left">–relaxed-isolation</td><td style="text-align:left">将连接事务隔离设置为读取未提交的映射器。</td></tr></tbody></table><h4 id="验证参数"><a href="#验证参数" class="headerlink" title="验证参数"></a>验证参数</h4><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–validate</td><td>启用复制数据的验证，仅支持单表复制。</td></tr><tr><td>–validator <class-name></class-name></td><td>指定要使用的验证程序类。</td></tr><tr><td>–validation-threshold <class-name></class-name></td><td>指定要使用的验证阈值类。</td></tr><tr><td>–validation-failurehandler <class-name></class-name></td><td>指定要使用的验证失败处理程序类。</td></tr></tbody></table><h3 id="B、导入控制参数："><a href="#B、导入控制参数：" class="headerlink" title="B、导入控制参数："></a>B、导入控制参数：</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–append</td><td>将数据附加到HDFS中的现有数据集</td></tr><tr><td>–as-avrodatafile</td><td>将数据导入Avro数据文件</td></tr><tr><td>–as-sequencefile</td><td>将数据导入SequenceFiles</td></tr><tr><td>–as-textfile</td><td>以纯文本格式导入数据（默认）</td></tr><tr><td>–as-parquetfile</td><td>将数据导入Parquet文件</td></tr><tr><td>–boundary-query <statement></statement></td><td>用于创建拆分的边界查询</td></tr><tr><td>–columns &lt;col,col,col…&gt;</td><td>要从表导入的列</td></tr><tr><td>–delete-target-dir</td><td>删除导入目标目录（如果存在）</td></tr><tr><td>–direct</td><td>如果数据库存在，请使用直接连接器</td></tr><tr><td>–fetch-size <n></n></td><td>一次从数据库中读取的条目数。</td></tr><tr><td>–inline-lob-limit <n></n></td><td>设置内联LOB的最大大小</td></tr><tr><td>-m,–num-mappers <n></n></td><td>使用<em>n个</em>映射任务并行导入</td></tr><tr><td>-e,–query <statement></statement></td><td>导入结果<em>statement</em>。</td></tr><tr><td>–split-by <column-name></column-name></td><td>用于拆分工作单位的表格列。不能与<code>--autoreset-to-one-mapper</code>选项一起使用</td></tr><tr><td>–split-limit <n></n></td><td>每个分割大小的上限。这仅适用于Integer和Date列。对于日期或时间戳字段，它以秒为单位计算</td></tr><tr><td>–autoreset-to-one-mapper</td><td>如果表没有主键且没有提供拆分列，则导入应使用一个映射器。不能与<code>--split-by &lt;col&gt;</code>选项一起使用</td></tr><tr><td>–table <table-name></table-name></td><td>要阅读的表格</td></tr><tr><td>–target-dir <dir></dir></td><td>HDFS目的地目录</td></tr><tr><td>–temporary-rootdir <dir></dir></td><td>导入期间创建的临时文件的HDFS目录（覆盖默认的“_sqoop”）</td></tr><tr><td>–warehouse-dir <dir></dir></td><td>表格目的地的HDFS父级</td></tr><tr><td>–where <where clause=""></where></td><td>导入期间要使用的WHERE子句</td></tr><tr><td>-z,–compress</td><td>启用压缩</td></tr><tr><td>–compression-codec <c></c></td><td>使用Hadoop编解码器（默认gzip）</td></tr><tr><td>–null-string <null-string></null-string></td><td>要为字符串列的空值写入的字符串</td></tr><tr><td>–null-non-string <null-string></null-string></td><td>要为非字符串列的空值写入的字符串</td></tr></tbody></table><p>在<code>--null-string</code>和<code>--null-non-string</code>参数都是可选的。\如果未指定，那么字符串“null”将被使用。</p><h3 id="C、连接到数据库"><a href="#C、连接到数据库" class="headerlink" title="C、连接到数据库"></a>C、连接到数据库</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc：mysql：//host0:3306/hive --username root --password 123456</span><br></pre></td></tr></table></figure><h3 id="D、自定义查询"><a href="#D、自定义查询" class="headerlink" title="D、自定义查询"></a>D、自定义查询</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用--query可以指定要使用表中的数据 注：value尽可能使用''，使用""需要在$前添加\,-m设置一次查询并发个数</span></span><br><span class="line">sqoop import --query<span class="string">'SELECT a.*，b.* from a JOIN b on（a.id == b.id）WHERE id &gt; 1202 and $CONDITIONS'</span> -m 1 --split-by a.id --target -dir / user / foo / joinresults</span><br></pre></td></tr></table></figure><h3 id="D、控制类型映射"><a href="#D、控制类型映射" class="headerlink" title="D、控制类型映射"></a>D、控制类型映射</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–map-column-java <mapping></mapping></td><td>为已配置的列覆盖从SQL到Java类型的映射。</td></tr><tr><td>–map-column-hive <mapping></mapping></td><td>为已配置的列覆盖从SQL到Hive类型的映射。</td></tr></tbody></table><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在--map-column-hive选项中指定逗号，您应该使用URL编码的键和值，例如，使用DECIMAL（1％2C％201）而不是DECIMAL（1,1）。</span></span><br><span class="line">sqoop import ... --map-column-java id = String，value = Integer</span><br></pre></td></tr></table></figure><h3 id="E、增量导入数据"><a href="#E、增量导入数据" class="headerlink" title="E、增量导入数据"></a>E、增量导入数据</h3><p><strong>Sqoop</strong>支持两种类型的增量导入：<code>append</code>和<code>lastmodified</code>。您可以使用该<code>--incremental</code>参数指定要执行的增量导入的类型。</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–check-column (col)</td><td>指定在确定要导入的行时要检查的列。（该列不应为CHAR / NCHAR / VARCHAR / VARNCHAR / LONGVARCHAR / LONGNVARCHAR类型）</td></tr><tr><td>–incremental (mode)</td><td>指定Sqoop确定哪些行是新的。<code>mode</code> 包含<code>append</code>和<code>lastmodified</code>。</td></tr><tr><td>–last-value (value)</td><td>指定上一个导入的检查列的最大值。</td></tr></tbody></table><p>增量数据导入分两种，一是基于<strong>递增列</strong>的增量数据导入（Append方式）。二是基于<strong>时间列</strong>的增量数据导入（LastModified方式）</p><h4 id="1、Append方式"><a href="#1、Append方式" class="headerlink" title="1、Append方式"></a>1、Append方式</h4><p>例：有一个订单表，里面每个订单有一个唯一标识自增列ID，在关系型数据库中以主键形式存在。之前已经将id在0~5201314之间的编号的订单导入到Hadoop中了（这里为HDFS），现在一段时间后我们需要将近期产生的新的订单数据导入Hadoop中（这里为HDFS），以供后续数仓进行分析。此时我们只需要指定–incremental 参数为append，–last-value参数为5201314即可。表示只从id大于5201314后开始导入。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://host0:3316/testdb --username root --password 123456 \</span><br><span class="line">--query <span class="string">"select order_id, name from order_table where \$CONDITIONS"</span> \</span><br><span class="line">--target-dir /user/root/orders_all \ </span><br><span class="line">--split-by order_id \</span><br><span class="line">-m 6  \</span><br><span class="line">--incremental append \</span><br><span class="line">--check-column order_id \</span><br><span class="line">--last-value 5201314</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–incremental append</td><td>基于递增列的增量导入（将递增列值大于阈值的所有数据增量导入Hadoop</td></tr><tr><td>–check-column</td><td>递增列（int）</td></tr><tr><td>–last-value</td><td>阈值（int）</td></tr></tbody></table><h4 id="2、Lastmodified方式"><a href="#2、Lastmodified方式" class="headerlink" title="2、Lastmodified方式"></a>2、Lastmodified方式</h4><p>此方式要求原有表中有time字段，它能指定一个时间戳，让Sqoop把该时间戳之后的数据导入至Hadoop（这里为HDFS）。因为后续订单可能状态会变化，变化后time字段时间戳也会变化，此时Sqoop依然会将相同状态更改后的订单导入HDFS，当然我们可以指定merge-key参数为orser_id，表示将后续新的记录与原有记录合并。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将时间列大于等于阈值的数据增量导入HDFS</span></span><br><span class="line"> sqoop import --connect jdbc:mysql://host0:3316/testdb --username root --password transwarp \</span><br><span class="line"> --query “select order_id, name from order_table <span class="built_in">where</span> \<span class="variable">$CONDITIONS</span>” \</span><br><span class="line"> --target-dir /user/root/order_all \ </span><br><span class="line"> --split-by id \</span><br><span class="line"> -m 4  \</span><br><span class="line"> --incremental lastmodified \</span><br><span class="line"> --merge-key order_id \</span><br><span class="line"> --check-column time \</span><br><span class="line"><span class="comment"># remember this date !!!</span></span><br><span class="line"> --last-value “2014-11-09 21:00:00”</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–incremental lastmodified</td><td>基于时间列的增量导入（将时间列大于等于阈值的所有数据增量导入Hadoop）</td></tr><tr><td>–check-column</td><td>时间列（int）</td></tr><tr><td>–last-value</td><td>阈值（int）</td></tr><tr><td>–merge-key</td><td>合并列（主键，合并键值相同的记录）</td></tr></tbody></table><h3 id="F、全量导入数据"><a href="#F、全量导入数据" class="headerlink" title="F、全量导入数据"></a>F、全量导入数据</h3><p><strong>全量数据导入</strong>就是一次性将所有需要导入的数据，从关系型数据库一次性地导入到Hadoop中（可以是HDFS、Hive等）。全量导入形式使用场景为一次性离线分析场景。用sqoop import命令，具体如下：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://host0:3306/testdb --username root --password 123456 \</span><br><span class="line">--query <span class="string">"select * from test_table where \$CONDITIONS"</span> \</span><br><span class="line">--target-dir /user/root/person_all \</span><br><span class="line">--fields-terminated-by <span class="string">","</span> \</span><br><span class="line">--hive-drop-import-delims --null-string <span class="string">"\\N"</span> --null-non-string <span class="string">"\\N"</span> \</span><br><span class="line">--split-by id \</span><br><span class="line">-m 6</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>– query</td><td>SQL查询语句</td></tr><tr><td>– target-dir</td><td>HDFS目标目录（确保目录不存在，否则会报错，因为Sqoop在导入数据至HDFS时会自己在HDFS上创建目录）</td></tr><tr><td>–hive-drop-import- delims</td><td>删除数据中包含的Hive默认分隔符（^A, ^B, \n）</td></tr><tr><td>–null-string</td><td>string类型空值的替换符（Hive中Null用\n表示）</td></tr><tr><td>–null-non-string</td><td>非string类型空值的替换符</td></tr><tr><td>–split-by</td><td>数据切片字段（int类型，m&gt;1时必须指定）</td></tr><tr><td>-m</td><td>Mapper任务数，默认为4</td></tr></tbody></table><h3 id="G、并发导入参数设置"><a href="#G、并发导入参数设置" class="headerlink" title="G、并发导入参数设置"></a>G、并发导入参数设置</h3><p>我们知道通过 <strong>-m</strong> 参数能够设置导入数据的 map 任务数量，即指定了 -m 即表示导入方式为并发导入，这时我们<strong>必须</strong>同时指定 <strong>- -split-by</strong> 参数指定根据哪一列来实现哈希分片，从而将不同分片的数据分发到不同 map 任务上去跑，<strong>避免数据倾斜</strong>。</p><ul><li>生产环境中，为了防止主库被Sqoop抽崩，我们一般从备库中抽取数据。</li><li>一般RDBMS的导出速度控制在60~80MB/s，每个 map 任务的处理速度5~10MB/s 估算，即 <strong>-m</strong> 参数一般设置<strong>4~8</strong>，表示启动 <strong>4~8</strong> 个map 任务并发抽取。</li></ul><h3 id="H、文件格式"><a href="#H、文件格式" class="headerlink" title="H、文件格式"></a>H、文件格式</h3><p>可以使用以下两种文件格式之一导入数据：分隔文本或SequenceFiles。</p><p>分隔文本是默认导入格式。您也可以使用<code>--as-textfile</code>参数显式指定它。此参数将每个记录的基于字符串的表示形式写入输出文件，并在各列和行之间使用分隔符。这些分隔符可以是逗号，制表符或其他字符。（可以选择分隔符;请参阅“输出行格式化参数。”）以下是基于文本的示例导入的结果：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1，这里有消息，2010-05-01 </span><br><span class="line">2，新年快乐！，2010-01-01 </span><br><span class="line">3，另有消息，2009-11-12</span><br></pre></td></tr></table></figure><p>分隔文本适用于大多数非二进制数据类型。它还很容易支持其他工具（如Hive）的进一步操作。</p><p><strong>SequenceFiles</strong>是一种<strong>二进制格式</strong>，用于将各个记录存储在自定义记录特定的数据类型中。这些数据类型表现为Java类。Sqoop会自动为您生成这些数据类型。此格式支持二进制表示中所有数据的精确存储，适用于存储二进制数据（例如，<code>VARBINARY</code>列），或者主要由自定义MapReduce程序操作的数据（从SequenceFiles读取比从文本文件读取更高的性能 ，<strong>因为记录不需要解析</strong>）。</p><p><strong>Avro</strong>数据文件是一种<strong>紧凑，高效</strong>的二进制格式，可提供与其他编程语言编写的应用程序的互操作性。Avro还支持版本控制，因此当例如在表中添加或删除列时，可以处理先前导入的数据文件以及新的数据文件。</p><p>默认情况下，不压缩数据。您可以使用deflate（gzip）算法和<code>-z</code>or <code>--compress</code> 参数压缩数据，或使用<code>--compression-codec</code>参数指定任何Hadoop压缩编解码器 。这适用于SequenceFile，文本和Avro文件。</p><h3 id="I、Hive参数"><a href="#I、Hive参数" class="headerlink" title="I、Hive参数"></a>I、Hive参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–hive-home <dir></dir></td><td>覆盖 <code>$HIVE_HOME</code></td></tr><tr><td>–hive-import</td><td>将表导入Hive（如果没有设置，则使用Hive的默认分隔符。）</td></tr><tr><td>–hive-overwrite</td><td>覆盖Hive表中的现有数据。</td></tr><tr><td>–create-hive-table</td><td>默认是false，如果目标表已经存在了，那么创建任务会失败</td></tr><tr><td>–hive-table <table-name></table-name></td><td>设置导入Hive时要使用的表名。</td></tr><tr><td>–hive-drop-import-delims</td><td>导入到Hive时从字符串字段中 删除<em>\ n</em>，<em>\ r</em>和<em>\ 01</em>。</td></tr><tr><td>–hive-delims-replacement</td><td>导入到Hive时，使用用户定义的字符串 替换字符串字段中的<em>\ n</em>，<em>\ r</em>和<em>\ 01</em>。</td></tr><tr><td>–hive-partition-key</td><td>指定hive分区名称</td></tr><tr><td>–hive-partition-value <v></v></td><td>指定分区的数值</td></tr><tr><td>–map-column-hive <map></map></td><td>为已配置的列覆盖从SQL类型到Hive类型的默认映射。</td></tr></tbody></table><h3 id="J、HBase参数"><a href="#J、HBase参数" class="headerlink" title="J、HBase参数"></a>J、HBase参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–column-family <family></family></td><td>设置导入的目标列族</td></tr><tr><td>–hbase-create-table</td><td>如果指定，则创建缺少的HBase表</td></tr><tr><td>–hbase-row-key <col></td><td>指定要用作行键的输入列，复合键必须要用逗号进行分隔</td></tr><tr><td>–hbase-table <table-name></table-name></td><td>指定要用作目标而不是HDFS的HBase表</td></tr><tr><td>–hbase-bulkload</td><td>启用批量加载</td></tr></tbody></table><h3 id="K、Accumulo参数"><a href="#K、Accumulo参数" class="headerlink" title="K、Accumulo参数"></a>K、Accumulo参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–accumulo-table <table-nam></table-nam></td><td>指定用作目标的Accumulo表而不是HDFS</td></tr><tr><td>–accumulo-column-family <family></family></td><td>设置导入的目标列族</td></tr><tr><td>–accumulo-create-table</td><td>如果指定，则创建缺少的Accumulo表</td></tr><tr><td>–accumulo-row-key <col></td><td>指定要用作行键的输入列</td></tr><tr><td>–accumulo-visibility <vis></vis></td><td>（可选）指定要应用于插入到Accumulo中的所有行的可见性标记。默认为空字符串。</td></tr><tr><td>-accumulo-batch-size <size></size></td><td>（可选）设置Accumulo写缓冲区的大小（以字节为单位）。默认值为4MB。</td></tr><tr><td>–accumulo-max-latency <ms></ms></td><td>（可选）设置Accumulo批处理编写器的最大延迟（以毫秒为单位）默认值为0</td></tr><tr><td>–accumulo-zookeepers <a href="host:port" target="_blank" rel="noopener">host:port</a></td><td>Accumulo实例使用的以逗号分隔的Zookeeper服务器列表</td></tr><tr><td>–accumulo-instance <table-name></table-name></td><td>目标Accumulo实例的名称</td></tr><tr><td>–accumulo-user <username></username></td><td>要导入的Accumulo用户的名称</td></tr><tr><td>–accumulo-password <password></password></td><td>Accumulo用户的密码</td></tr></tbody></table><h2 id="3、sqoop-export"><a href="#3、sqoop-export" class="headerlink" title="3、sqoop-export"></a>3、sqoop-export</h2><h3 id="A、导出控制参数"><a href="#A、导出控制参数" class="headerlink" title="A、导出控制参数"></a>A、导出控制参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–columns &lt;col,col,col…&gt;</td><td>要导出到表的列</td></tr><tr><td>–direct</td><td>使用直接导出快速路径</td></tr><tr><td>–export-dir <dir></dir></td><td>导出的HDFS源路径</td></tr><tr><td>-m,–num-mappers <n></n></td><td>使用<em>n个</em>映射任务并行导出</td></tr><tr><td>–table <table-name></table-name></td><td>表名</td></tr><tr><td>–call <stored-proc-name></stored-proc-name></td><td>存储过程调用</td></tr><tr><td>–update-key <col-name></col-name></td><td>用于更新列。如果有多个列，请使用逗号分隔的列列表。</td></tr><tr><td>–update-mode <mode></mode></td><td><code>mode</code>包含 <code>updateonly</code>（默认）和<code>allowinsert</code>。</td></tr><tr><td>–input-null-string <null-string></null-string></td><td>字符串列的解释为null的字符串</td></tr><tr><td>–input-null-non-string <null-string></null-string></td><td>对于非字符串列，要解释为null的字符串</td></tr><tr><td>–staging-table <staging-table-name></staging-table-name></td><td>在插入目标表之前将暂存数据的表。</td></tr><tr><td>–clear-staging-table</td><td>表示可以删除表中存在的任何数据。</td></tr><tr><td>–batch</td><td>使用批处理模式执行基础语句。</td></tr></tbody></table><p>在<code>--input-null-string</code>和<code>--input-null-non-string</code>参数都是可选的。如果<code>--input-null-string</code>未指定，则对于字符串类型的列，字符串“null”将被解释为null。如果<code>--input-null-non-string</code>未指定，则对于非字符串列，字符串“null”和空字符串都将被解释为null。请注意，除了指定的其他字符串之外，对于非字符串列，空字符串将始终被解释为null <code>--input-null-non-string</code>。</p><p>由于Sqoop将导出过程分解为多个事务，因此失败的导出作业可能会导致将部分数据提交到数据库。这可能进一步导致后续作业由于某些情况下的插入冲突而失败，或导致其他作业中的重复数据。您可以通过<code>--staging-table</code>选项指定登台表来解决此问题，该选项充当用于暂存导出数据的辅助表。分阶段数据最终在单个事务中移动到目标表。</p><p><strong>–update-mode</strong>模式有两种<strong>updateonly</strong>（默认）和<strong>allowinsert</strong></p><p><strong>updateonly</strong>：该模式用于更新Hive表与目标表中数据的不一致，即在不一致时，将Hive中的数据同步给目标表（如MySQL、Oracle等的目标表中），这种不一致是指，一条记录中的不一致，比如Hive表和MySQL中都有一个id=1的记录，但是其中一个字段的取值不同，则该模式会将这种差异抹除。对于“你有我无”的记录则“置之不理”。</p><p><strong>allowinsert</strong>：该模式用于将Hive中有但目标表中无的记录同步到目标表中，但同时也会同步不一致的记录。可以这种模式可以包含updateony模式的操作，这也是为什么没有命名为insertonly的原因吧。</p><p><strong>updateonly</strong>模式只会更新表中修改的数据，不会更新新增的数据；allowinsert模式既可以更新修改的数据也可以更新新增的数据。</p><p>B、输入解析参数</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–input-enclosed-by <char></char></td><td>设置必填字段包含</td></tr><tr><td>–input-escaped-by <char></char></td><td>设置输入转义字符</td></tr><tr><td>–input-fields-terminated-by <char></char></td><td>设置输入字段分隔符</td></tr><tr><td>–input-lines-terminated-by <char></char></td><td>设置输入行分隔符</td></tr><tr><td>–input-optionally-enclosed-by <char></char></td><td>设置包含字符的字段</td></tr></tbody></table><p>C、输出行格式参数</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–enclosed-by <char></char></td><td>设置包含字符的必填字段</td></tr><tr><td>–escaped-by <char></char></td><td>设置转义字符</td></tr><tr><td>–fields-terminated-by <char></char></td><td>设置字段分隔符</td></tr><tr><td>–lines-terminated-by <char></char></td><td>设置行尾字符</td></tr><tr><td>–mysql-delimiters</td><td>使用MySQL的默认分隔符集：fields: ‘,’ lines:<code>\n</code> escaped-by:<code>\</code> optional-enclosed-by:<code>&#39;</code></td></tr><tr><td>–optionally-enclosed-by <char></char></td><td>设置包含字符的字段</td></tr></tbody></table><h2 id="4、Sqoop常用操作"><a href="#4、Sqoop常用操作" class="headerlink" title="4、Sqoop常用操作"></a>4、Sqoop常用操作</h2><p>从外部数据库导入到Hadoop上时用import，反之用export。</p><h3 id="A、MySQL-gt-HDFS"><a href="#A、MySQL-gt-HDFS" class="headerlink" title="A、MySQL-&gt;HDFS"></a>A、MySQL-&gt;HDFS</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#--target-dir /user/sqoop/hive hive文件夹要不存在或使用--delete-target-dir删除已存在的文件夹</span></span><br><span class="line">sqoop import --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table VERSION --columns <span class="string">"name,age"</span> --<span class="built_in">where</span> <span class="string">"age&gt;18"</span> \</span><br><span class="line">--default-character-set = utf8 \</span><br><span class="line">--target-dir /user/sqoop/hive \</span><br><span class="line">--delete-target-dir \</span><br><span class="line">--fields-terminated-by <span class="string">','</span> \<span class="comment">#导入数据后每个字段的分隔符</span></span><br><span class="line">--split-by age \</span><br><span class="line">-m 1 \</span><br><span class="line"></span><br><span class="line">--incremental append \</span><br><span class="line">--null-string <span class="string">''</span>\ <span class="comment">#导入字段为空时，指定字符串替换</span></span><br><span class="line">--check-column id \ <span class="comment">#指定增量导入时的参考列</span></span><br><span class="line">--last-value 10<span class="comment">#上次导入后的值</span></span><br></pre></td></tr></table></figure><h3 id="B、MySQL-gt-Hive"><a href="#B、MySQL-gt-Hive" class="headerlink" title="B、MySQL-&gt;Hive"></a>B、MySQL-&gt;Hive</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--hive中创建表</span></span><br><span class="line"><span class="keyword">use</span> <span class="keyword">default</span>;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">exists</span> default.hive_bbs_product_snappy ;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> default.hive_bbs_product_snappy(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line">brand_id <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="keyword">string</span></span><br><span class="line"> )</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span> ;</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sqoop将数据导入到Hive</span></span><br><span class="line">sqoop import --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table bbs_product \</span><br><span class="line">--delete-target-dir \</span><br><span class="line"></span><br><span class="line">--hive-import \</span><br><span class="line">--create-hive-table \</span><br><span class="line">--hive-database default \</span><br><span class="line">--hive-table hive_bbs_product_snappy \</span><br><span class="line">--hive-overwrite \<span class="comment">#重写数据</span></span><br><span class="line">--fields-terminated-by <span class="string">'\t'</span> \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line"></span><br><span class="line">--incremental append \</span><br><span class="line">--null-string <span class="string">''</span>\ <span class="comment">#导入字段为空时，指定字符串替换</span></span><br><span class="line">--check-column id \ <span class="comment">#指定增量导入时的参考列</span></span><br><span class="line">--last-value 10<span class="comment">#上次导入后的值</span></span><br></pre></td></tr></table></figure><h3 id="C、MySQL-gt-HBase"><a href="#C、MySQL-gt-HBase" class="headerlink" title="C、MySQL-&gt;HBase"></a>C、MySQL-&gt;HBase</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--mysql创建表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> tohdfs(</span><br><span class="line"><span class="keyword">id</span> <span class="built_in">int</span>,</span><br><span class="line"><span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">20</span>))</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据导入HBase并在HBase中创建表</span></span><br><span class="line">sqoop import --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table tohdfs  \</span><br><span class="line"></span><br><span class="line">--hbase-table hbase_tohdfs \</span><br><span class="line">--column-family info  \</span><br><span class="line">--hbase-create-table \</span><br><span class="line">--hbase-row-key id \</span><br><span class="line">--fields-terminated-by <span class="string">'\t'</span> \</span><br><span class="line">--num-mappers 1 \</span><br><span class="line"></span><br><span class="line">--incremental append \</span><br><span class="line">--null-string <span class="string">''</span>\ <span class="comment">#导入字段为空时，指定字符串替换</span></span><br><span class="line">--check-column id \ <span class="comment">#指定增量导入时的参考列</span></span><br><span class="line">--last-value 10<span class="comment">#上次导入后的值</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用--hbase-bulkload</span></span><br><span class="line">sqoop import --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table tohdfs  \</span><br><span class="line"></span><br><span class="line">--hbase-table hbase_tohdfs_bulk \</span><br><span class="line">--column-family info  \</span><br><span class="line">--hbase-create-table \                     </span><br><span class="line">--hbase-row-key id \</span><br><span class="line">--hbase-bulkload</span><br></pre></td></tr></table></figure><h3 id="D、HDFS-gt-MySQL"><a href="#D、HDFS-gt-MySQL" class="headerlink" title="D、HDFS-&gt;MySQL"></a>D、HDFS-&gt;MySQL</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table tohdfs \</span><br><span class="line">--<span class="built_in">export</span>-dir /tmp/datathree/  \<span class="comment">#HDFS的目录位置</span></span><br><span class="line">-m 1 \</span><br><span class="line">--input-fields-terminated-by <span class="string">'\0001'</span></span><br></pre></td></tr></table></figure><h3 id="E、Hive-gt-MySQL"><a href="#E、Hive-gt-MySQL" class="headerlink" title="E、Hive-&gt;MySQL"></a>E、Hive-&gt;MySQL</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#方法一为将Hive表所在的数据位置（HDFS）导入到MySQL中</span></span><br><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:mysql://host0:3306/hive --username root --password 123456 \</span><br><span class="line">--table wht_test2 \</span><br><span class="line">--<span class="built_in">export</span>-dir /user/hive/warehouse/wht_test1 \</span><br><span class="line">--input-fields-terminated-by <span class="string">'\0001'</span> \</span><br><span class="line">-m 1</span><br><span class="line"><span class="comment">#--fields-terminated-by '\t' \#HDFS中被导出的文件字段的间隔符</span></span><br></pre></td></tr></table></figure><h3 id="F、HBase-gt-MySQL"><a href="#F、HBase-gt-MySQL" class="headerlink" title="F、HBase-&gt;MySQL"></a>F、HBase-&gt;MySQL</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#HBASE-&gt;Hive映射表-&gt;Hive内部表-&gt;MySQL</span></span><br><span class="line"><span class="comment">#1、MySQL创建表</span></span><br><span class="line">create table test.employee(</span><br><span class="line">rowkey int(11),</span><br><span class="line">id int(11),</span><br><span class="line">name varchar(20),</span><br><span class="line">primary key (id))</span><br><span class="line"><span class="comment">#2、HBase创建表</span></span><br><span class="line">create <span class="string">'employee'</span>,<span class="string">'info'</span></span><br><span class="line">put <span class="string">'employee'</span>,1,<span class="string">'info:id'</span>,1</span><br><span class="line">put <span class="string">'employee'</span>,1,<span class="string">'info:name'</span>,peter</span><br><span class="line"><span class="comment">#3、Hive创建映射表</span></span><br><span class="line">create external table test.h_employee(key int,id int,name string)</span><br><span class="line">STORED BY <span class="string">'org.apache.hadoop.hive.hbase.HBaseStorageHandler'</span></span><br><span class="line">WITH SERDEPROPERTIES(</span><br><span class="line"><span class="string">"hbase.columns.mapping"</span> = <span class="string">":key,info:id,info:name"</span></span><br><span class="line">)</span><br><span class="line">TBLPROPERTIES(<span class="string">"hbase.table.name"</span>=<span class="string">"employee"</span>,</span><br><span class="line"><span class="string">"hbase.mapred.output.outputable"</span>=<span class="string">"employee"</span>);</span><br><span class="line"><span class="comment">#4、Hive创建内部表</span></span><br><span class="line">create table test.employee(key INT,id INT,name STRING);</span><br><span class="line">insert overwrite table test.employee select * from test.h_employee;</span><br><span class="line"><span class="comment">#5、sqoop导出hive表到MySQL</span></span><br><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:mysql://host0:3306/<span class="built_in">test</span> --username root --password 123456 \</span><br><span class="line">--table employee \</span><br><span class="line">-<span class="built_in">export</span>-dir /user/hive/warehouse/test.db/employee \</span><br><span class="line">--input-fields-terminated-by <span class="string">'\001'</span> \</span><br><span class="line">--input-null-string <span class="string">'\\N'</span> \</span><br><span class="line">--input-null-non-string <span class="string">'\\N'</span></span><br></pre></td></tr></table></figure><h3 id="G、Oracle-gt-HDFS"><a href="#G、Oracle-gt-HDFS" class="headerlink" title="G、Oracle-&gt;HDFS"></a>G、Oracle-&gt;HDFS</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:oracle:thin:@IPAddress:databaseName \</span><br><span class="line">--username userName --password password \</span><br><span class="line">--table TABLENAME \</span><br><span class="line">--target-dir /user/operate \</span><br><span class="line">-m 1 --<span class="built_in">where</span> <span class="string">"where子句 and 根据需要添加"</span></span><br></pre></td></tr></table></figure><h3 id="H、Oracle-gt-Hive"><a href="#H、Oracle-gt-Hive" class="headerlink" title="H、Oracle-&gt;Hive"></a>H、Oracle-&gt;Hive</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:oracle:thin:@IPAddress:1521:databaseName \</span><br><span class="line">--username userName --password password \</span><br><span class="line">--table TABLENAME  \</span><br><span class="line">-m 1 --hive-import --hive-database <span class="built_in">test</span></span><br></pre></td></tr></table></figure><h3 id="I、HDFS-gt-Oracle"><a href="#I、HDFS-gt-Oracle" class="headerlink" title="I、HDFS-&gt;Oracle"></a>I、HDFS-&gt;Oracle</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:oracle:thin:@//192.168.27.235:1521/ORCL \</span><br><span class="line">--username scott --password liujiyu \</span><br><span class="line">--table empty \</span><br><span class="line">--<span class="built_in">export</span>-dir <span class="string">'/liujiyu/nihao/part-m-00000'</span> \</span><br><span class="line">--fields-terminated-by <span class="string">':'</span> \</span><br><span class="line">-m  1</span><br></pre></td></tr></table></figure><p>J、Hive-&gt;Oracle</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span></span><br><span class="line"><span class="comment"># 指定要从Hive中导出的表</span></span><br><span class="line">--table TABLE_NAME    </span><br><span class="line"><span class="comment"># host_ip:导入oracle库所在的ip:导入的数据库</span></span><br><span class="line">--connect jdbc:oracle:thin:@HOST_IP:DATABASE_NAME </span><br><span class="line"></span><br><span class="line"><span class="comment"># oracle用户账号</span></span><br><span class="line">--username USERNAME</span><br><span class="line"><span class="comment"># oracle用户密码</span></span><br><span class="line">--password PASSWORD </span><br><span class="line"></span><br><span class="line"><span class="comment"># hive表数据文件在hdfs上的路径</span></span><br><span class="line">--<span class="built_in">export</span>-dir /user/hive/<span class="built_in">test</span>/TABLE_NAME</span><br><span class="line"><span class="comment"># 指定表的列名，必须指定 </span></span><br><span class="line">--columns ID,data_date,data_type,c1,c2,c3 </span><br><span class="line"></span><br><span class="line"><span class="comment"># 列分隔符(根据hive的表结构定义指定分隔符)</span></span><br><span class="line">--input-fields-terminated-by <span class="string">'\001'</span></span><br><span class="line"><span class="comment"># 行分隔符</span></span><br><span class="line">--input-lines-terminated-by <span class="string">'\n'</span> </span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果hive表中存在null字段，则需要添加参数，否则无法导入</span></span><br><span class="line">--input-null-string <span class="string">'\\N'</span> </span><br><span class="line">--input-null-non-string <span class="string">'\\N'</span></span><br></pre></td></tr></table></figure><h2 id="5、数据验证-Validation"><a href="#5、数据验证-Validation" class="headerlink" title="5、数据验证-Validation"></a>5、数据验证-Validation</h2><p>通过比较源和目标表的行计数来验证复制的数据正确性。</p><h3 id="验证器"><a href="#验证器" class="headerlink" title="验证器"></a><strong>验证器</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">属性：validator</span><br><span class="line">描述：用于验证的驱动程序，必须实现org.apache.sqoop.validation.Validator </span><br><span class="line">支持的值：该值必须是完全限定的类名。</span><br><span class="line">默认值：org.apache.sqoop.validation.RowCountValidator</span><br></pre></td></tr></table></figure><h3 id="验证阈值"><a href="#验证阈值" class="headerlink" title="验证阈值"></a><strong>验证阈值</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">属性：validation-threshold </span><br><span class="line">描述：根据满足阈值的验证驱动决策。必须实现org.apache.sqoop.validation.ValidationThreshold </span><br><span class="line">支持的值：该值必须是完全限定的类名。</span><br><span class="line">默认值：org.apache.sqoop.validation.AbsoluteValidationThreshold</span><br></pre></td></tr></table></figure><h3 id="验证失败处理程序"><a href="#验证失败处理程序" class="headerlink" title="验证失败处理程序"></a><strong>验证失败处理程序</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">属性：validation-failurehandler </span><br><span class="line">描述：负责处理失败，必须实现org.apache.sqoop.validation.ValidationFailureHandler </span><br><span class="line">支持的值：该值必须是完全限定的类名。</span><br><span class="line">默认值：org.apache.sqoop.validation.AbortOnFailureHandler</span><br></pre></td></tr></table></figure><h3 id="限制"><a href="#限制" class="headerlink" title="限制"></a><strong>限制</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">验证当前仅验证从单个表复制到HDFS的数据。以下是当前运行中的限制：</span><br><span class="line">1、所有表格选项</span><br><span class="line">2、自由格式查询选项</span><br><span class="line">3、数据导入Hive，HBase或Accumulo</span><br><span class="line">4、使用--where参数导入表</span><br><span class="line">5、增量进口</span><br></pre></td></tr></table></figure><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a><strong>示例</strong></h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --connect jdbc:mysql://host0:3306/<span class="built_in">test</span> --username root --password 123456 \</span><br><span class="line">--table bar \ </span><br><span class="line">--<span class="built_in">export</span> -dir /results/bar_data \</span><br><span class="line">--validate</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --connect jdbc:mysql://host0:3306/<span class="built_in">test</span> --username root --password 123456 \</span><br><span class="line">--table employee \ </span><br><span class="line">--validate --validator org.apache.sqoop.validation.RowCountValidator \ </span><br><span class="line">--validation-threshold org.apache.sqoop.validation.AbsoluteValidationThreshold \ </span><br><span class="line">--validation-failurehandler org.apache.sqoop.validation.AbortOnFailureHandler</span><br></pre></td></tr></table></figure><h2 id="6、sqoop-job"><a href="#6、sqoop-job" class="headerlink" title="6、sqoop-job"></a>6、sqoop-job</h2><p>允许您创建和处理已保存的作业。保存的作业记住用于指定作业的参数，因此可以通过命令调用作业来重新执行它们。</p><p>如果将已保存的作业配置为增量导入，则会在已保存的作业中更新有关最近导入的行的状态，以允许作业仅连续导入最新的行。</p><h3 id="选项参数"><a href="#选项参数" class="headerlink" title="选项参数"></a><strong>选项参数</strong></h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–create <job-id></job-id></td><td>定义新的作业</td></tr><tr><td>–delete <job-id></job-id></td><td>删除已保存的作业</td></tr><tr><td>–exec <job-id></job-id></td><td>运行已保存的作业</td></tr><tr><td>–show <job-id></job-id></td><td>显示已保存作业的参数</td></tr><tr><td>–list</td><td>列出所有已保存的作业</td></tr></tbody></table><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a><strong>示例</strong></h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop job --create myjob  -import --connect jdbc:mysql://host0:3306/<span class="built_in">test</span> \</span><br><span class="line">--username root --password 123456 \</span><br><span class="line">--table mytable</span><br></pre></td></tr></table></figure><h2 id="7、sqoop-merge"><a href="#7、sqoop-merge" class="headerlink" title="7、sqoop-merge"></a>7、sqoop-merge</h2><p>合并工具允许您组合两个数据集，其中一个数据集中的条目应覆盖旧数据集的条目。例如，在最后修改模式下的增量导入运行将在HDFS中生成多个数据集，其中每个数据集中会连续出现更新的数据。该<code>merge</code> 工具将两个数据集“展平”为一个，获取每个主键的最新可用记录。</p><h3 id="选项参数-1"><a href="#选项参数-1" class="headerlink" title="选项参数"></a>选项参数</h3><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–class-name <class></class></td><td>指定在合并作业期间要使用的特定于记录的类的名称。</td></tr><tr><td>–jar-file <file></file></td><td>指定要从中加载记录类的jar的名称。</td></tr><tr><td>–merge-key <col></td><td>指定要用作合并键的列的名称。</td></tr><tr><td>–new-data <path></path></td><td>指定较新数据集的路径。</td></tr><tr><td>–onto <path></path></td><td>指定旧数据集的路径。</td></tr><tr><td>–target-dir <path></path></td><td>指定合并作业输出的目标路径。</td></tr></tbody></table><p>该<code>merge</code>工具运行MapReduce作业，该作业将两个目录作为输入：较新的数据集和较旧的数据集。这些分别用<code>--new-data</code>和指定 <code>--onto</code>。MapReduce作业的输出将放在由指定的HDFS目录中<code>--target-dir</code>。</p><p>合并数据集时，假设每条记录中都有唯一的主键值。主键的列用<code>--merge-key</code>。指定。同一数据集中的多个行不应具有相同的主键，否则可能会发生数据丢失。</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop merge --new-data newer --onto older --target-dir merged --merge-key id</span><br></pre></td></tr></table></figure><h2 id="8、Oracle连接器"><a href="#8、Oracle连接器" class="headerlink" title="8、Oracle连接器"></a>8、Oracle连接器</h2><h3 id="Oracle用户要有以下权限"><a href="#Oracle用户要有以下权限" class="headerlink" title="Oracle用户要有以下权限"></a>Oracle用户要有以下权限</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">用户必须具有<span class="keyword">select</span> <span class="keyword">any</span> dictionary privilege或select_catalog_role角色或以下所有对象权限：</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> v_$<span class="keyword">instance</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_tables</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_tab_columns</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_objects</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_extents</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_segments - 仅适用于Sqoop导入</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_constraints - 仅适用于Sqoop导入</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> v_$<span class="keyword">database</span> - 仅适用于Sqoop导入</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> v_$parameter - 仅适用于Sqoop导入</span><br></pre></td></tr></table></figure><h3 id="导出数据时需要的额外权限"><a href="#导出数据时需要的额外权限" class="headerlink" title="导出数据时需要的额外权限"></a>导出数据时需要的额外权限</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_tab_partitions</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_tab_subpartitions</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_indexes</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">on</span> dba_ind_columns</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">any</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">any</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">any</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">any</span> <span class="keyword">table</span> （分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">insert</span> <span class="keyword">on</span> <span class="keyword">table</span> （没有分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">alter</span> <span class="keyword">on</span> <span class="keyword">table</span> （分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">update</span> <span class="keyword">on</span> <span class="keyword">table</span> （没有分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">delete</span>,<span class="keyword">alter</span>,<span class="keyword">insert</span> <span class="keyword">on</span> <span class="keyword">table</span> （分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">insert</span>,<span class="keyword">update</span> <span class="keyword">on</span> <span class="keyword">table</span> （没有分区）</span><br><span class="line"><span class="keyword">select</span>,<span class="keyword">insert</span>,<span class="keyword">delete</span>,<span class="keyword">alter</span> <span class="keyword">on</span> <span class="keyword">table</span> （分区）</span><br></pre></td></tr></table></figure><h3 id="支持的数据类型"><a href="#支持的数据类型" class="headerlink" title="支持的数据类型"></a>支持的数据类型</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">BINARY_DOUBLENCLOB</span><br><span class="line">BINARY_FLOATNUMBER</span><br><span class="line">BLOBNVARCHAR2</span><br><span class="line">CHARRAW</span><br><span class="line">CLOBROWID</span><br><span class="line">DATETIMESTAMP</span><br><span class="line">FLOATTIMESTAMP <span class="keyword">WITH</span> <span class="built_in">TIME</span> ZONE</span><br><span class="line"><span class="built_in">INTERVAL</span> <span class="keyword">DAY</span> <span class="keyword">TO</span> <span class="keyword">SECOND</span><span class="built_in">TIMESTAMP</span> <span class="keyword">WITH</span> <span class="keyword">LOCAL</span> <span class="built_in">TIME</span> ZONE</span><br><span class="line"><span class="built_in">INTERVAL</span> <span class="keyword">YEAR</span> <span class="keyword">TO</span> <span class="keyword">MONTH</span>URITYPE</span><br><span class="line"><span class="keyword">LONG</span>VARCHAR2</span><br><span class="line"><span class="keyword">NCHAR</span></span><br></pre></td></tr></table></figure><h3 id="连接Oracle"><a href="#连接Oracle" class="headerlink" title="连接Oracle"></a>连接Oracle</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">--connect jdbc:oracle:thin:@OracleServer:OraclePort:OracleSID</span><br><span class="line">--connect jdbc:oracle:thin:@//OracleServer:OraclePort/OracleService</span><br><span class="line">--connect jdbc:oracle:thin:@TNSName</span><br></pre></td></tr></table></figure><h3 id="从Oracle导入数据"><a href="#从Oracle导入数据" class="headerlink" title="从Oracle导入数据"></a>从Oracle导入数据</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop import --direct --connect … --table OracleTableName</span><br><span class="line">-Dmapred.child.java.opts=-Xmx4000M <span class="comment">#设置JVM内存</span></span><br></pre></td></tr></table></figure><h3 id="Hadoop文件与Oracle表分区匹配"><a href="#Hadoop文件与Oracle表分区匹配" class="headerlink" title="Hadoop文件与Oracle表分区匹配"></a>Hadoop文件与Oracle表分区匹配</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-Doraoop.chunk.method=&#123;ROWID|PARTITION&#125;</span><br><span class="line">要以这样的方式从分区表导入数据，使得Hadoop中生成的HDFS文件夹结构与表的分区匹配，请将块方法设置为PARTITION。替代（默认）块方法是ROWID。</span><br><span class="line"></span><br><span class="line">注： 要使Hadoop文件的数量与Oracle分区的数量相匹配，请将映射器的数量设置为大于或等于分区数。</span><br><span class="line">  如果表未分区，则值PARTITION将导致错误。</span><br></pre></td></tr></table></figure><h3 id="指定导入的分区"><a href="#指定导入的分区" class="headerlink" title="指定导入的分区"></a>指定导入的分区</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">-Doraoop.import.partitions=PartitionA,PartitionB --table OracleTableName</span><br><span class="line">注： <span class="string">""</span>中保留大小写，<span class="string">''</span>自动将名称转换为大写</span><br><span class="line">使用双引号时，整个分区名称列表必须用单引号括起来。</span><br><span class="line">如果列表中的最后一个分区名称是双引号，则列表末尾必须有逗号。</span><br><span class="line">-Doraoop.import.partitions=<span class="string">'"PartitionA","PartitionB",'</span> --table OracleTableName</span><br></pre></td></tr></table></figure><h3 id="数据导出到Oracle"><a href="#数据导出到Oracle" class="headerlink" title="数据导出到Oracle"></a>数据导出到Oracle</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sqoop <span class="built_in">export</span> --direct --connect … --table OracleTableName --<span class="built_in">export</span>-dir /user/username/tablename</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> BigData </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BigData </tag>
            
            <tag> ETL </tag>
            
            <tag> Sqoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用命令</title>
      <link href="/2019/06/04/linux-chang-yong-ming-ling/"/>
      <url>/2019/06/04/linux-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<h2 id="一、压缩命令"><a href="#一、压缩命令" class="headerlink" title="一、压缩命令"></a>一、压缩命令</h2><p>默认压缩级别情况下,1.8G数据 压缩大小: gzip (462M) &gt; bzip2 (238M) &gt; xz (44M)</p><h3 id="1、bzip2、bunzip2"><a href="#1、bzip2、bunzip2" class="headerlink" title="1、bzip2、bunzip2"></a><strong>1、bzip2、bunzip2</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">压缩单个文件命令 压缩后demo.txt消失，生成demo.txt.bz2文件</span></span><br><span class="line">bzip2 demo.txt</span><br><span class="line"><span class="meta">#</span><span class="bash">解压命令</span></span><br><span class="line">bunzip2 demo.txt.bz2</span><br><span class="line"><span class="meta">#</span><span class="bash">压缩多个文件命令</span></span><br><span class="line">bzip2 demo1.txt demo2.txt</span><br><span class="line"><span class="meta">#</span><span class="bash">解压多个文件命令</span></span><br><span class="line">bunzip2 demo1.txt.bz2 demo2.txt.bz2</span><br></pre></td></tr></table></figure><h3 id="2、gzip"><a href="#2、gzip" class="headerlink" title="2、gzip"></a><strong>2、gzip</strong></h3><p>gzip只能对普通文件进行压缩和解压</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">压缩命令</span></span><br><span class="line">gzip demo.txt</span><br><span class="line"><span class="meta">#</span><span class="bash">压缩并保留源文件</span></span><br><span class="line">gzip -c demo.txt &gt; demo.txt.gz</span><br><span class="line"><span class="meta">#</span><span class="bash">解压命令</span></span><br><span class="line">gzip -d demo.txt.gz</span><br></pre></td></tr></table></figure><h3 id="3、tar"><a href="#3、tar" class="headerlink" title="3、tar"></a><strong>3、tar</strong></h3><p>tar是打包、拆包的命令</p><p>“打包/拆包”“压缩/解压缩”有什么区别？我们用一个生活中的例子来解释：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- 就像搬家时，我们把每一床棉被都抽成真空，这叫作压缩，然后把好几床抽真空的棉被用绳子捆绑起来，这就叫打包。</span><br><span class="line">- 东西搬到新家后，把绳子解开，就是拆包，然后把每床棉被舒展开，让棉被松软起来，这就是解压缩。</span><br><span class="line">- 如果不抽真空，只是把几床棉被简单地用绳子捆起来，那么就单独用tar就好了。</span><br><span class="line">- 如果只有一床棉被，打算抽真空，那么就用gzip就好了。</span><br><span class="line">- 如果有好多床棉被，既要抽真空，又要捆起来，那么就要将tar和gzip结合起来使用。</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">拆包解压</span></span><br><span class="line">tar -xvf demo.tar</span><br><span class="line">tar -xvzf demo.tar.gz</span><br><span class="line">tar -xvjf demo.tar.bz2</span><br><span class="line"><span class="meta">#</span><span class="bash">打包压缩 将/var/<span class="built_in">log</span>下的文件打包解压到名为demo.tar.gz的文件夹</span></span><br><span class="line">tar -cvf demo.tar /var/log#仅打包，不压缩</span><br><span class="line">tar -cvzf demo.tar.gz /var/log#打包后用gzip压缩</span><br><span class="line">tar -cvjf demo.tar.bz2 /var/log#打包后用bzip2压缩</span><br><span class="line"><span class="meta">#</span><span class="bash">参数解释</span></span><br><span class="line">-c 表示进行打包动作</span><br><span class="line">-z 使用gzip进行压缩和解压</span><br><span class="line">-v 显示整个过程</span><br><span class="line">-f 指定要打包的文件</span><br><span class="line">-x 表示进行拆包动作</span><br><span class="line">-j 使用bzip2进行压缩和解压</span><br><span class="line">-t 显示包中的内容</span><br><span class="line"><span class="meta">#</span><span class="bash">显示压缩包中的内容，但是不解压</span></span><br><span class="line">tar -tvzf demo.tar.gz</span><br></pre></td></tr></table></figure><h2 id="二、端口监听"><a href="#二、端口监听" class="headerlink" title="二、端口监听"></a>二、端口监听</h2>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL语句不会触发索引的原因</title>
      <link href="/2019/04/18/sql-yu-ju-bu-hui-hong-fa-suo-yin-de-yuan-yin/"/>
      <url>/2019/04/18/sql-yu-ju-bu-hui-hong-fa-suo-yin-de-yuan-yin/</url>
      
        <content type="html"><![CDATA[<h2 id="1、查询谓词没有使用索引的主要边界-换句话说就是select-，可能会导致不走索引。"><a href="#1、查询谓词没有使用索引的主要边界-换句话说就是select-，可能会导致不走索引。" class="headerlink" title="1、查询谓词没有使用索引的主要边界,换句话说就是select *，可能会导致不走索引。"></a>1、<strong>查询谓词没有使用索引的主要边界,换句话说就是select *，可能会导致不走索引。</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">比如，你查询的是<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> Y=XXX;</span><br><span class="line">假如你的T表上有一个包含Y值的组合索引，但是优化器会认为需要一行行的扫描会更有效，这个时候，优化器可能会选择TABLE ACCESS FULL，但是如果换成了<span class="keyword">SELECT</span> Y <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> Y = XXX，优化器会直接去索引中找到Y的值，因为从B树中就可以找到相应的值。</span><br><span class="line"></span><br><span class="line">解决方法：进行表信息统计或使用<span class="keyword">Analyze</span>进行分析</span><br></pre></td></tr></table></figure><h2 id="2、单键值的b树索引列上存在null值，导致COUNT-不能走索引。"><a href="#2、单键值的b树索引列上存在null值，导致COUNT-不能走索引。" class="headerlink" title="2、单键值的b树索引列上存在null值，导致COUNT(*)不能走索引。"></a>2、<strong>单键值的b树索引列上存在null值，导致COUNT(*)不能走索引。</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">如果在B树索引中有一个空值，那么查询诸如<span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> T 的时候，因为HASHSET中不能存储空值的，所以优化器不会走索引，有两种方式可以让索引有效，一种是<span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> XXX <span class="keyword">IS</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>或者把这个列的属性改为<span class="keyword">not</span> <span class="literal">null</span> (不能为空)。</span><br></pre></td></tr></table></figure><h2 id="3、索引列上有函数运算，导致不走索引"><a href="#3、索引列上有函数运算，导致不走索引" class="headerlink" title="3、索引列上有函数运算，导致不走索引"></a>3、<strong>索引列上有函数运算，导致不走索引</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">如果在T表上有一个索引Y，但是你的查询语句是这样子<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> FUN(Y) = XXX。这个时候索引也不会被用到。</span><br><span class="line">因为你要查询的列中所有的行都需要被计算一遍，因此，如果要让这种<span class="keyword">sql</span>语句的效率提高的话，在这个表上建立一个基于函数的索引，比如<span class="keyword">CREATE</span> <span class="keyword">INDEX</span> IDX FUNT <span class="keyword">ON</span> T(FUN(Y));这种方式，等于数据库会建立一个存储所有函数计算结果的值，再进行查询的时候就不需要进行计算了，因为很多函数存在不同返回值，因此必须标明这个函数是有固定返回值的。</span><br></pre></td></tr></table></figure><h2 id="4、隐式转换导致不走索引。"><a href="#4、隐式转换导致不走索引。" class="headerlink" title="4、隐式转换导致不走索引。"></a>4、<strong>隐式转换导致不走索引。</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">索引不适用于隐式转换的情况，比如你的<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> Y = <span class="number">5</span> 在Y上面有一个索引，但是Y列是VARCHAR2的，那么<span class="keyword">Oracle</span>会将上面的<span class="number">5</span>进行一个隐式的转换，<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T <span class="keyword">WHERE</span> TO_NUMBER(Y) = <span class="number">5</span>,这个时候也是有可能用不到索引的。</span><br></pre></td></tr></table></figure><h2 id="5、表的数据库小或者需要选择大部分数据，不走索引"><a href="#5、表的数据库小或者需要选择大部分数据，不走索引" class="headerlink" title="5、表的数据库小或者需要选择大部分数据，不走索引"></a>5、表的数据库小或者需要选择大部分数据，不走索引</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">在数据库的初始化参数中，有一个参数是一次读取的数据块的数目，比如你的表只有几个数据块大小，而且可以被数据库一次性抓取，那么就没有使用索引的必要了，因为抓取索引还需要去根据rowid从数据块中获取相应的元素值，因此在表特别小的情况下，索引没有用到是情理当中的事情。</span><br></pre></td></tr></table></figure><h2 id="6、cbo优化器下统计信息不准确，导致不走索引"><a href="#6、cbo优化器下统计信息不准确，导致不走索引" class="headerlink" title="6、cbo优化器下统计信息不准确，导致不走索引"></a>6、cbo优化器下统计信息不准确，导致不走索引</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">很长时间没有做表分析，或者重新收集表状态信息了，在数据字典中，表的统计信息是不准确的，这个情况下，可能会使用错误的索引，这个效率可能也是比较低的。</span><br></pre></td></tr></table></figure><h2 id="7、！-或者-lt-gt-不等于），可能导致不走索引，也可能走-INDEX-FAST-FULL-SCAN"><a href="#7、！-或者-lt-gt-不等于），可能导致不走索引，也可能走-INDEX-FAST-FULL-SCAN" class="headerlink" title="7、！=或者&lt;&gt;(不等于），可能导致不走索引，也可能走 INDEX FAST FULL SCAN"></a>7、！=或者&lt;&gt;(不等于），可能导致不走索引，也可能走 INDEX FAST FULL SCAN</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">例如<span class="keyword">select</span> <span class="keyword">id</span>  <span class="keyword">from</span> <span class="keyword">test</span> <span class="keyword">where</span> <span class="keyword">id</span>&lt;&gt;<span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="8、表字段的属性导致不走索引"><a href="#8、表字段的属性导致不走索引" class="headerlink" title="8、表字段的属性导致不走索引"></a>8、表字段的属性导致不走索引</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">字符型的索引列会导致优化器认为需要扫描索引大部分数据且聚簇因子很大，最终导致弃用索引扫描而改用全表扫描方式，</span><br><span class="line"></span><br><span class="line">由于字符型和数值型的在<span class="keyword">insert</span>的时候排序不同，字符类型导致了聚簇因子很大，原因是插入顺序与排序顺序不同。详细点说，就是按照数字类型插入（<span class="number">1.</span><span class="number">.3200000</span>），按字符类型（<span class="string">'1'</span>...<span class="string">'32000000'</span>）t排序，在对字符类型使用大于运算符时，会导致优化器认为需要扫描索引大部分数据且聚簇因子很大，最终导致弃用索引扫描而改用全表扫描方式。</span><br><span class="line"></span><br><span class="line">解决方法</span><br><span class="line">将<span class="keyword">SQL</span>语句由开放区间扫描（&gt;=），修改为封闭区间（<span class="keyword">between</span> xxx <span class="keyword">and</span> max_value）。使得数据在索引局部顺序是“对的”。如果采用这种方式仍然不走索引扫描，还可以进一步细化分段或者采用“逐条提取+批绑定”的方法。</span><br></pre></td></tr></table></figure><h2 id="9、建立组合索引，但查询谓词并未使用组合索引的第一列"><a href="#9、建立组合索引，但查询谓词并未使用组合索引的第一列" class="headerlink" title="9、建立组合索引，但查询谓词并未使用组合索引的第一列"></a>9、<strong>建立组合索引，但查询谓词并未使用组合索引的第一列</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">查询谓词并未使用组合索引的第一列,此处有一个INDEX SKIP SCAN概念,如创建索引A（id,name）</span><br><span class="line">无法使用索引案例：<span class="keyword">select</span> <span class="keyword">type</span> <span class="keyword">from</span> T <span class="keyword">where</span> <span class="keyword">name</span> = <span class="string">'AA'</span>;</span><br><span class="line">可以使用索引案例：<span class="keyword">select</span> <span class="keyword">type</span> <span class="keyword">from</span> T <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">111</span>;</span><br></pre></td></tr></table></figure><h2 id="10、like-‘-xxx’-百分号在前"><a href="#10、like-‘-xxx’-百分号在前" class="headerlink" title="10、like ‘%xxx’ 百分号在前"></a>10、<strong>like ‘%xxx’ 百分号在前</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'%aa'</span></span><br></pre></td></tr></table></figure><h2 id="11、not-in-not-exist"><a href="#11、not-in-not-exist" class="headerlink" title="11、not in ,not exist"></a>11、<strong>not in ,not exist</strong></h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">可以尝试把not in 或者 not exists 改成左连接的方式（前提是有子查询，并且子查询有where条件）。</span><br></pre></td></tr></table></figure><p>总结：关系型数据库中有很多情况会导致index失效，并且走全表扫描的代价是相当大的，所以在写sql的时候一定要注意这个会使索引失效的情况，养成良好的习惯。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL优化 </tag>
            
            <tag> SQL优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL语句优化</title>
      <link href="/2019/04/12/sql-yu-ju-you-hua/"/>
      <url>/2019/04/12/sql-yu-ju-you-hua/</url>
      
        <content type="html"><![CDATA[<p>怎么加快查询速度，优化查询效率，主要原则就是应尽量避免全表扫描，应该考虑在where及order by 涉及的列上建立索引。</p><p>建立索引不是建的越多越好，原则是：</p><p>①、一个表的索引不是越多越好，也没有一个具体的数字，根据以往的经验，<strong>一个表的索引最多不能超过6个，</strong>因为索引越多，对update和insert操作也会有性能的影响，涉及到索引的新建和重建操作。</p><p>②、建立索引的方法论为：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1. 多数查询经常使用的列；</span><br><span class="line">2. 很少进行修改操作的列；</span><br><span class="line">3. 索引需要建立在数据差异化大的列上</span><br></pre></td></tr></table></figure><h2 id="SQL优化分类"><a href="#SQL优化分类" class="headerlink" title="SQL优化分类"></a><strong>SQL优化分类</strong></h2><h3 id="1、sql语句模型结构优化指导"><a href="#1、sql语句模型结构优化指导" class="headerlink" title="1、sql语句模型结构优化指导"></a><strong>1、sql语句模型结构优化指导</strong></h3><h4 id="①、-ORDER-BY-LIMIT组合的索引优化"><a href="#①、-ORDER-BY-LIMIT组合的索引优化" class="headerlink" title="①、 ORDER BY + LIMIT组合的索引优化"></a><strong>①、 ORDER BY + LIMIT组合的索引优化</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--如果一个SQL语句形如</span></span><br><span class="line"><span class="keyword">SELECT</span> [column1],[column2],…. <span class="keyword">FROM</span> [<span class="keyword">TABLE</span>] <span class="keyword">ORDER</span> <span class="keyword">BY</span> [<span class="keyword">sort</span>] <span class="keyword">LIMIT</span> [<span class="keyword">offset</span>],[<span class="keyword">LIMIT</span>];</span><br><span class="line"><span class="comment">--这个SQL语句优化比较简单，在[sort]这个栏位上建立索引即可。</span></span><br></pre></td></tr></table></figure><h4 id="②、-WHERE-ORDER-BY-LIMIT组合的索引优化"><a href="#②、-WHERE-ORDER-BY-LIMIT组合的索引优化" class="headerlink" title="②、 WHERE + ORDER BY + LIMIT组合的索引优化"></a><strong>②、 WHERE + ORDER BY + LIMIT组合的索引优化</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--如果一个SQL语句形如</span></span><br><span class="line"><span class="keyword">SELECT</span> [column1],[column2],…. <span class="keyword">FROM</span> [<span class="keyword">TABLE</span>] <span class="keyword">WHERE</span> [columnX] = [<span class="keyword">VALUE</span>] <span class="keyword">ORDER</span> <span class="keyword">BY</span> [<span class="keyword">sort</span>] <span class="keyword">LIMIT</span> [<span class="keyword">offset</span>],[<span class="keyword">LIMIT</span>];</span><br><span class="line"><span class="comment">--这个语句，如果你仍然采用第一个例子中建立索引的方法，虽然可以用到索引，但是效率不高。更高效的方法是建立一个联合索引(columnX,sort)</span></span><br></pre></td></tr></table></figure><h4 id="③、WHERE-ORDER-BY多个栏位-LIMIT"><a href="#③、WHERE-ORDER-BY多个栏位-LIMIT" class="headerlink" title="③、WHERE+ORDER BY多个栏位+LIMIT"></a><strong>③、WHERE+ORDER BY多个栏位+LIMIT</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- 如果一个SQL语句形如</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> [<span class="keyword">table</span>] <span class="keyword">WHERE</span> uid=<span class="number">1</span> <span class="keyword">ORDER</span> x,y <span class="keyword">LIMIT</span> <span class="number">0</span>,<span class="number">10</span>;</span><br><span class="line"><span class="comment">-- 对于这个语句，大家可能是加一个这样的索引:(x,y,uid)。但实际上更好的效果是(uid,x,y)。这是由MySQL处理排序的机制造成的。</span></span><br></pre></td></tr></table></figure><h3 id="2、复合索引"><a href="#2、复合索引" class="headerlink" title="2、复合索引"></a><strong>2、复合索引</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--形如(x,y,uid)索引的索引</span></span><br><span class="line"><span class="comment">--如果一个SQL语句形如</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> area =’beijing’ <span class="keyword">and</span> age=<span class="number">22</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">--如果我们是在area和age上分别创建索引的话，由于mysql查询每次只能使用一个索引，所以虽然这样已经相对不做索引时全表扫描提高了很多效率，但是如果area，age两列上创建复合索引的话将带来更高的效率。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--例如我们建立了一个这样的索引（area,age,salary），那么其实相当于创建了（area,age,salary）,(area,age),(area)三个索引，这样称为最佳左前缀特性。</span></span><br></pre></td></tr></table></figure><h3 id="3、like语句优化"><a href="#3、like语句优化" class="headerlink" title="3、like语句优化"></a><strong>3、like语句优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'%abc%'</span></span><br><span class="line"><span class="comment">--由于abc前面用了“%”，因此该查询必然走全表查询，除非必要，否则不要在关键词前加%，优化成如下</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">name</span> <span class="keyword">like</span> <span class="string">'abc%'</span></span><br></pre></td></tr></table></figure><h3 id="4、where子句使用-！-或-lt-gt-操作符优化"><a href="#4、where子句使用-！-或-lt-gt-操作符优化" class="headerlink" title="4、where子句使用 ！= 或 &lt;&gt; 操作符优化"></a><strong>4、where子句使用 ！= 或 &lt;&gt; 操作符优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--在where子句中使用 ！= 或 &lt;&gt;操作符，索引将被放弃使用，会进行全表查询。</span></span><br><span class="line">如SQL:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">ID</span> != <span class="number">5</span> 优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">ID</span>&gt;<span class="number">5</span> <span class="keyword">OR</span> <span class="keyword">ID</span>&lt;<span class="number">5</span></span><br></pre></td></tr></table></figure><h3 id="5、where子句中使用-IS-NULL-或-IS-NOT-NULL-的优化"><a href="#5、where子句中使用-IS-NULL-或-IS-NOT-NULL-的优化" class="headerlink" title="5、where子句中使用 IS NULL 或 IS NOT NULL 的优化"></a><strong>5、where子句中使用 IS NULL 或 IS NOT NULL 的优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--在where子句中使用 IS NULL 或 IS NOT NULL 判断，索引将被放弃使用，会进行全表查询。</span></span><br><span class="line">如SQL:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">IS</span> <span class="literal">NULL</span> </span><br><span class="line"><span class="comment">--优化成num上设置默认值0，确保表中num没有null值，</span></span><br><span class="line">然后<span class="keyword">SQL</span>为：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span>=<span class="number">0</span></span><br></pre></td></tr></table></figure><h3 id="6、where子句使用or的优化"><a href="#6、where子句使用or的优化" class="headerlink" title="6、where子句使用or的优化"></a><strong>6、where子句使用or的优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--很多时候使用union all 或 nuin(必要的时候)的方式替换“or”会得到更好的效果。</span></span><br><span class="line"><span class="comment">--where子句中使用了or,索引将被放弃使用。</span></span><br><span class="line">如SQL:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> =<span class="number">10</span> <span class="keyword">or</span> <span class="keyword">num</span> = <span class="number">20</span> </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> = <span class="number">10</span> <span class="keyword">union</span> all <span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span>=<span class="number">20</span></span><br></pre></td></tr></table></figure><h3 id="7、where子句使用IN-或-NOT-IN的优化"><a href="#7、where子句使用IN-或-NOT-IN的优化" class="headerlink" title="7、where子句使用IN 或 NOT IN的优化"></a><strong>7、where子句使用IN 或 NOT IN的优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--in和not in 也要慎用，否则也会导致全表扫描。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--方案一：between替换in</span></span><br><span class="line">如SQL:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">in</span>(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>) </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">between</span> <span class="number">1</span> <span class="keyword">and</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--方案二：exist替换in</span></span><br><span class="line">如<span class="keyword">SQL</span>:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">in</span>(<span class="keyword">select</span> <span class="keyword">num</span> <span class="keyword">from</span> b ) </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">num</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">exists</span>(<span class="keyword">select</span> <span class="number">1</span> <span class="keyword">from</span> B <span class="keyword">where</span> B.num = A.num)</span><br><span class="line"></span><br><span class="line"><span class="comment">--方案三：left join替换in</span></span><br><span class="line">如<span class="keyword">SQL</span>:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> <span class="keyword">in</span>(<span class="keyword">select</span> <span class="keyword">num</span> <span class="keyword">from</span> B) </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> B <span class="keyword">ON</span> A.num = B.num</span><br></pre></td></tr></table></figure><h3 id="8、where子句中对字段进行表达式操作的优化"><a href="#8、where子句中对字段进行表达式操作的优化" class="headerlink" title="8、where子句中对字段进行表达式操作的优化"></a><strong>8、where子句中对字段进行表达式操作的优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--不要在where子句中的“=”左边进行函数、算数运算或其他表达式运算，否则系统将可能无法正确使用索引。</span></span><br><span class="line">如SQL:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span>/<span class="number">2</span> = <span class="number">100</span> </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">num</span> = <span class="number">100</span>*<span class="number">2</span></span><br><span class="line"></span><br><span class="line">如<span class="keyword">SQL</span>:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">substring</span>(<span class="keyword">name</span>,<span class="number">1</span>,<span class="number">3</span>) = <span class="string">'abc'</span> </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">LIKE</span> <span class="string">'abc%'</span></span><br><span class="line"></span><br><span class="line">如<span class="keyword">SQL</span>:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">datediff</span>(<span class="keyword">day</span>,createdate,<span class="string">'2016-11-30'</span>)=<span class="number">0</span> </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> createdate&gt;=<span class="string">'2016-11-30'</span> <span class="keyword">and</span> createdate&lt;<span class="string">'2016-12-1'</span></span><br><span class="line"></span><br><span class="line">如<span class="keyword">SQL</span>:<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">year</span>(addate) &lt;<span class="number">2016</span> </span><br><span class="line">优化成：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">where</span> addate&lt;<span class="string">'2016-01-01'</span></span><br></pre></td></tr></table></figure><h3 id="9、尽量避免select-from"><a href="#9、尽量避免select-from" class="headerlink" title="9、尽量避免select * from　"></a><strong>9、尽量避免select * from</strong>　</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">任何地方都不要用 <span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">table</span> ，用具体的字段列表替换 <span class="string">"*"</span>，不要返回用不到的字段</span><br></pre></td></tr></table></figure><h3 id="10、使用“临时表”暂存中间结果"><a href="#10、使用“临时表”暂存中间结果" class="headerlink" title="10、使用“临时表”暂存中间结果"></a><strong>10、使用“临时表”暂存中间结果</strong></h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">采用临时表暂存中间结果好处：</span><br><span class="line">1）避免程序中多次扫描主表，减少程序执行“共享锁”阻塞“更新锁”，减少了阻塞，提高了并发性能。</span><br><span class="line">2）尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。</span><br><span class="line">3）避免频繁创建和删除临时表，以减少系统资源的浪费。</span><br><span class="line">4）尽量避免向客户端返回大数据量，若数据量过大，应考虑相应需求是否合理。</span><br></pre></td></tr></table></figure><h3 id="11、limit分页优化"><a href="#11、limit分页优化" class="headerlink" title="11、limit分页优化"></a><strong>11、limit分页优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">当偏移量特别时，limit效率会非常低</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">LIMIT</span> <span class="number">1000</span>,<span class="number">10</span>   很快</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">LIMIT</span> <span class="number">90000</span>,<span class="number">10</span> 很慢</span><br><span class="line"></span><br><span class="line"><span class="comment">--优化方法：</span></span><br><span class="line">方法一：<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> A <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">limit</span> <span class="number">90000</span>,<span class="number">10</span>; </span><br><span class="line">很快，0.04秒就OK。 因为用了id主键做索引当然快</span><br><span class="line">方法二：<span class="keyword">select</span> <span class="keyword">id</span>,title <span class="keyword">from</span> A <span class="keyword">where</span> <span class="keyword">id</span>&gt;=(<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> <span class="keyword">collect</span> <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">id</span> <span class="keyword">limit</span> <span class="number">90000</span>,<span class="number">1</span>) <span class="keyword">limit</span> <span class="number">10</span>;</span><br><span class="line">方法三：<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> A <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">id</span>  <span class="keyword">between</span> <span class="number">10000000</span> <span class="keyword">and</span> <span class="number">10000010</span>;</span><br></pre></td></tr></table></figure><h3 id="12、批量插入优化"><a href="#12、批量插入优化" class="headerlink" title="12、批量插入优化"></a><strong>12、批量插入优化</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> person(<span class="keyword">name</span>,age) <span class="keyword">values</span>(<span class="string">'A'</span>,<span class="number">14</span>)</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> person(<span class="keyword">name</span>,age) <span class="keyword">values</span>(<span class="string">'B'</span>,<span class="number">14</span>)</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> person(<span class="keyword">name</span>,age) <span class="keyword">values</span>(<span class="string">'C'</span>,<span class="number">14</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">--可优化为：</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> person(<span class="keyword">name</span>,age) <span class="keyword">values</span>(<span class="string">'A'</span>,<span class="number">14</span>),(<span class="string">'B'</span>,<span class="number">14</span>),(<span class="string">'C'</span>,<span class="number">14</span>)</span><br></pre></td></tr></table></figure><h3 id="13、利用limit-1-、top-1-取得一行"><a href="#13、利用limit-1-、top-1-取得一行" class="headerlink" title="13、利用limit 1 、top 1 取得一行"></a><strong>13、利用limit 1 、top 1 取得一行</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--有时要查询一张表时，你知道只需要看一条记录，你可能去查询一条特殊的记录。可以使用limit 1 或者 top 1 来终止数据库索引继续扫描整个表或索引。</span></span><br><span class="line">如SQL：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">LIKE</span> <span class="string">'abc%'</span> 优化为：<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">FROM</span> A <span class="keyword">LIKE</span> <span class="string">'abc%'</span> <span class="keyword">limit</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="14、尽量不要使用-BY-RAND-命令"><a href="#14、尽量不要使用-BY-RAND-命令" class="headerlink" title="14、尽量不要使用 BY RAND()命令"></a><strong>14、尽量不要使用 BY RAND()命令</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- BY RAND()是随机显示结果，这个函数可能会为表中每一个独立的行执行BY RAND()命令，这个会消耗处理器的处理能力。</span></span><br><span class="line"></span><br><span class="line">如SQL：<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> A <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">rand</span>() <span class="keyword">limit</span> <span class="number">10</span> </span><br><span class="line">优化为：<span class="keyword">SELECT</span> * <span class="keyword">FROM</span> A <span class="keyword">WHERE</span> <span class="keyword">id</span> &gt;= ((<span class="keyword">SELECT</span> <span class="keyword">MAX</span>(<span class="keyword">id</span>) <span class="keyword">FROM</span> A)-(<span class="keyword">SELECT</span> <span class="keyword">MIN</span>(<span class="keyword">id</span>) <span class="keyword">FROM</span> A)) * <span class="keyword">RAND</span>() + (<span class="keyword">SELECT</span> <span class="keyword">MIN</span>(<span class="keyword">id</span>) <span class="keyword">FROM</span> A) <span class="keyword">LIMIT</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><h3 id="15、排序的索引问题"><a href="#15、排序的索引问题" class="headerlink" title="15、排序的索引问题　"></a><strong>15、排序的索引问题</strong>　</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--Mysql查询只是用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。</span></span><br><span class="line"><span class="comment">--因此数据库默认排序可以符合要求情况下不要使用排序操作；</span></span><br><span class="line"><span class="comment">--尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。</span></span><br></pre></td></tr></table></figure><h3 id="16、尽量用-union-add-替换-union"><a href="#16、尽量用-union-add-替换-union" class="headerlink" title="16、尽量用 union add 替换 union"></a><strong>16、尽量用 union add 替换 union</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--union和union all的差异主要是前者需要将两个（或者多个）结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的cpu运算，加大资源消耗及延迟。</span></span><br><span class="line"><span class="comment">--所以当我们可以确认不可能出现重复结果集或者不在乎重复结果集的时候，尽量使用union all而不是union</span></span><br></pre></td></tr></table></figure><h3 id="17、避免类型转换"><a href="#17、避免类型转换" class="headerlink" title="17、避免类型转换"></a><strong>17、避免类型转换</strong></h3><figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="comment">--这里所说的“类型转换”是指where子句中出现column字段的类型和传入的参数类型不一致的时候发生的类型转换。人为的上通过转换函数进行转换，直接导致mysql无法使用索引。如果非要转型，应该在传入参数上进行转换。</span></span><br><span class="line">例如 utime 是 datetime 类型，传入的参数是 “ 2016-07-23 ”</span><br><span class="line">在比较大小时通常是 date（utime）&gt;"2016-07-23"</span><br><span class="line">可以优化为utime&gt;"2016-07-23 00：00：00"</span><br></pre></td></tr></table></figure><h3 id="18、尽可能使用更小的字段"><a href="#18、尽可能使用更小的字段" class="headerlink" title="18、尽可能使用更小的字段　"></a><strong>18、尽可能使用更小的字段</strong>　</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--MySQL从磁盘读取数据后是存储到内存中的，然后使用cpu周期和磁盘I/O读取它，这意味着越小的数据类型占用的空间越小，从磁盘读或打包到内存的效率都更好，但也不要太过执着减小数据类型，要是以后应用程序发生什么变化就没有空间了。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--修改表将需要重构，间接地可能引起代码的改变，这是很头疼的问题，因此需要找到一个平衡点。</span></span><br></pre></td></tr></table></figure><h3 id="19、Inner-join-和-left-join、right-join、子查询"><a href="#19、Inner-join-和-left-join、right-join、子查询" class="headerlink" title="19、Inner join 和 left join、right join、子查询"></a><strong>19、Inner join 和 left join、right join、子查询</strong></h3><h4 id="第一：inner-join内连接也叫等值连接，left-right-join是外连接。"><a href="#第一：inner-join内连接也叫等值连接，left-right-join是外连接。" class="headerlink" title="第一：inner join内连接也叫等值连接，left/right join是外连接。"></a><strong>第一：inner join内连接也叫等值连接，left/right join是外连接。</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> A.id,A.name,B.id,B.name <span class="keyword">FROM</span> A <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> B <span class="keyword">ON</span> A.id =B.id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A.id,A.name,B.id,B.name <span class="keyword">FROM</span> A <span class="keyword">RIGHT</span> <span class="keyword">JOIN</span> <span class="keyword">ON</span> B A.id= B.id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A.id,A.name,B.id,B.name <span class="keyword">FROM</span> A <span class="keyword">INNER</span> <span class="keyword">JOIN</span> <span class="keyword">ON</span> A.id =B.id;</span><br><span class="line"><span class="comment">--经过来之多方面的证实inner join性能比较快，因为inner join是等值连接，或许返回的行数比较少。但是我们要记得有些语句隐形的用到了等值连接，如：</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">SELECT</span> A.id,A.name,B.id,B.name <span class="keyword">FROM</span> A,B <span class="keyword">WHERE</span> A.id = B.id;</span><br><span class="line"><span class="comment">--推荐：能用 inner join 连接尽量使用 inner join 连接</span></span><br></pre></td></tr></table></figure><h4 id="第二：子查询的性能又比外连接性能慢，尽量用外连接来替换子查询。"><a href="#第二：子查询的性能又比外连接性能慢，尽量用外连接来替换子查询。" class="headerlink" title="第二：子查询的性能又比外连接性能慢，尽量用外连接来替换子查询。"></a><strong>第二：子查询的性能又比外连接性能慢，尽量用外连接来替换子查询。</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Select</span> * <span class="keyword">from</span> A <span class="keyword">where</span> <span class="keyword">exists</span> (<span class="keyword">select</span> * <span class="keyword">from</span> B <span class="keyword">where</span> <span class="keyword">id</span>&gt;=<span class="number">3000</span> <span class="keyword">and</span> A.uuid=B.uuid);</span><br><span class="line"></span><br><span class="line"><span class="comment">--A表的数据为十万级表，B表为百万级表，在本机执行差不多用2秒左右，我们可以通过explain可以查看到子查询是一个相关子查询(DEPENDENCE SUBQUERY);Mysql是先对外表A执行全表查询，然后根据uuid逐次执行子查询，如果外层表是一个很大的表，我们可以想象查询性能会表现比这个更加糟糕。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--一种简单的优化就是用innerjoin的方法来代替子查询，查询语句改为：</span></span><br><span class="line"><span class="keyword">Select</span>* <span class="keyword">from</span> A <span class="keyword">inner</span> <span class="keyword">join</span> B <span class="keyword">ON</span> A.uuid=B.uuid <span class="keyword">using</span>(<span class="keyword">uuid</span>) <span class="keyword">where</span> b.uuid&gt;=<span class="number">3000</span>; </span><br><span class="line"><span class="comment">--这个语句执行测试不到一秒；</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--第三：使用JOIN时候，应该用小的结果join大的结果（left join 左边表结果尽量小，如果有条件应该放到左边先处理，right join同理反向），同时尽量把牵涉到多表联合的查询拆分多个query</span></span><br><span class="line"><span class="comment">--多个表查询效率低，容易锁表和阻塞</span></span><br><span class="line"><span class="comment">--如：</span></span><br><span class="line"><span class="keyword">Select</span> * <span class="keyword">from</span> A <span class="keyword">left</span> <span class="keyword">join</span> B A.id=B.ref_id <span class="keyword">where</span>  A.id&gt;<span class="number">10</span>;</span><br><span class="line"><span class="comment">--可以优化为：</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> (<span class="keyword">select</span> * <span class="keyword">from</span> A wehre <span class="keyword">id</span> &gt;<span class="number">10</span>) T1 <span class="keyword">left</span> <span class="keyword">join</span> B <span class="keyword">on</span> T1.id=B.ref_id;</span><br></pre></td></tr></table></figure><h3 id="20、exist-代替-in"><a href="#20、exist-代替-in" class="headerlink" title="20、exist 代替 in"></a><strong>20、exist 代替 in</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> A <span class="keyword">WHERE</span> idin (<span class="keyword">SELECT</span> <span class="keyword">id</span> <span class="keyword">from</span> B)</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">from</span> A <span class="keyword">WHERE</span> <span class="keyword">id</span> <span class="keyword">EXISTS</span>(<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">from</span> A.id= B.id)</span><br><span class="line"><span class="comment">--in 是在内存中遍历比较</span></span><br><span class="line"><span class="comment">--exist 需要查询数据库，所以当B的数据量比较大时，exists效率优于in.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--in()只执行一次，把B表中的所有id字段缓存起来，之后检查A表的id是否与B表中的id相等，如果id相等则将A表的记录加入到结果集中，直到遍历完A表的所有记录。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--In 操作的流程原理如同一下代码</span></span><br><span class="line">  <span class="keyword">List</span> resultSet=&#123;&#125;;</span><br><span class="line"></span><br><span class="line">    Array A=(<span class="keyword">select</span> * <span class="keyword">from</span> A);</span><br><span class="line">    Array B=(<span class="keyword">select</span> <span class="keyword">id</span> <span class="keyword">from</span> B);</span><br><span class="line"></span><br><span class="line">    for(int i=0;i&lt;A.length;i++) &#123;</span><br><span class="line">            for(int j=0;j&lt;B.length;j++) &#123;</span><br><span class="line">          if(A[i].id==B[j].id) &#123;</span><br><span class="line">             resultSet.add(A[i]);</span><br><span class="line">             break;</span><br><span class="line">          &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return resultSet;   </span><br><span class="line">    </span><br><span class="line"><span class="comment">--可以看出，当B表数据较大时不适合使用in()，因为它会B表数据全部遍历一次</span></span><br><span class="line"><span class="comment">--如：A表有10000条记录，B表有1000000条记录，那么最多有可能遍历10000*1000000次，效率很差。</span></span><br><span class="line"><span class="comment">--再如：A表有10000条记录，B表有100条记录，那么最多有可能遍历10000*100次，遍历次数大大减少，效率大大提升。</span></span><br><span class="line"><span class="comment">--结论：in()适合B表比A表数据小的情况</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--exist()会执行A.length()次，执行过程代码如下</span></span><br><span class="line">    List resultSet=&#123;&#125;;</span><br><span class="line">    Array A=(<span class="keyword">select</span> * <span class="keyword">from</span> A);</span><br><span class="line">    for(int i=0;i&lt;A.length;i++) &#123;</span><br><span class="line">       if(exists(A[i].id) &#123;  //执行select 1 from B where B.id=A.id是否有记录返回</span><br><span class="line">           resultSet.add(A[i]);</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return resultSet;</span><br><span class="line">          </span><br><span class="line"><span class="comment">--当B表比A表数据大时适合使用exists()，因为它没有那么多遍历操作，只需要再执行一次查询就行。</span></span><br><span class="line"><span class="comment">--如：A表有10000条记录，B表有1000000条记录，那么exists()会执行10000次去判断A表中的id是否与B表中的id相等。</span></span><br><span class="line"><span class="comment">--如：A表有10000条记录，B表有100000000条记录，那么exists()还是执行10000次，因为它只执行A.length次，可见B表数据越多，越适合exists()发挥效果。</span></span><br><span class="line"><span class="comment">--再如：A表有10000条记录，B表有100条记录，那么exists()还是执行10000次，还不如使用in()遍历10000*100次，因为in()是在内存里遍历比较，而exists()需要查询数据库，</span></span><br><span class="line"><span class="comment">--我们都知道查询数据库所消耗的性能更高，而内存比较很快。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--结论：exists()适合B表比A表数据大的情况</span></span><br><span class="line"><span class="comment">--当A表数据与B表数据一样大时，in与exists效率差不多，可任选一个使用。</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL综合优化</title>
      <link href="/2019/04/11/sql-zong-he-you-hua/"/>
      <url>/2019/04/11/sql-zong-he-you-hua/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL如何实现优化？"><a href="#MySQL如何实现优化？" class="headerlink" title="MySQL如何实现优化？"></a><strong>MySQL如何实现优化？</strong></h2><h3 id="1、数据库设计要合理（3F）"><a href="#1、数据库设计要合理（3F）" class="headerlink" title="1、数据库设计要合理（3F）"></a>1、<strong>数据库设计要合理</strong>（3F）</h3><h4 id="1F-原子约束"><a href="#1F-原子约束" class="headerlink" title="1F 原子约束"></a>1F <strong>原子约束</strong></h4><p>当关系模式R的所有属性都不能在分解为更基本的数据单位时，称R是满足第一范式的，简记为1NF。简单的来说就是列无法再进行分割。</p><p> ①、每一列属性都是不可再分的属性值，确保每一列的原子性</p><p> ②、两列的属性相近或相似或一样，尽量合并属性一样的列，确保不产生冗余数据。</p><h4 id="2F保证唯一性"><a href="#2F保证唯一性" class="headerlink" title="2F保证唯一性"></a>2F<strong>保证唯一性</strong></h4><p>主键 （不能用id作为订单号码，订单号码利用分布式锁提前将订单号生成好，存放在redis中，需要的话直接去redis中获取 ）</p><p>每一行的数据只能与其中一列相关，即一行数据只做一件事。只要数据列中出现数据重复，就要把表拆分开来。</p><h4 id="3F不要有冗余数据"><a href="#3F不要有冗余数据" class="headerlink" title="3F不要有冗余数据"></a>3F<strong>不要有冗余数据</strong></h4><p>id    name    address    classid    classname</p><p>1    a        北京        1        chinese</p><p>2    b        北京        2        math</p><p>数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。像：a–&gt;b–&gt;c  属性之间含有这样的关系，是不符合第三范式的。</p><p>比如Student表（学号，姓名，年龄，性别，所在院校，院校地址，院校电话）</p><p>这样一个表结构，就存在上述关系。 学号–&gt; 所在院校 –&gt; (院校地址，院校电话)</p><p>这样的表结构，我们应该拆开来，如下。</p><p>（学号，姓名，年龄，性别，所在院校）–（所在院校，院校地址，院校电话）</p><h3 id="2、添加索引"><a href="#2、添加索引" class="headerlink" title="2、添加索引"></a>2、<strong>添加索引</strong></h3><h5 id="①索引的定义"><a href="#①索引的定义" class="headerlink" title="①索引的定义"></a><strong>①索引的定义</strong></h5><p>　　数据库索引好比是一本书前面的目录，能加快数据库的查询速度。<a href="http://baike.baidu.com/view/262241.htm" target="_blank" rel="noopener">索引</a>是对数据库表中一个或多个列（例如，employee 表的姓氏 (lname) 列）的值进行排序的结构。如果想按特定职员的姓来查找他或她，则与在表中搜索所有的行相比，索引有助于更快地获取信息。</p><h5 id="②建立索引的优缺点："><a href="#②建立索引的优缺点：" class="headerlink" title="②建立索引的优缺点："></a><strong>②建立索引的优缺点：</strong></h5><h6 id="优点："><a href="#优点：" class="headerlink" title="优点："></a><strong>优点</strong>：</h6><p>​    1.大大加快数据的检索速度;<br>​    2.创建唯一性索引，保证数据库表中每一行数据的唯一性;<br>​    3.加速表和表之间的连接;<br>​    4.在使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间。</p><h6 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a><strong>缺点</strong>：</h6><p>　　1.索引需要占用数据表以外的物理存储空间</p><p>　　2.创建索引和维护索引要花费一定的时间</p><p>　　3.当对表进行更新操作时，索引需要被重建，这样降低了数据的维护速度。</p><h5 id="③、索引类型"><a href="#③、索引类型" class="headerlink" title="③、索引类型"></a><strong>③、索引类型</strong></h5><p>索引分为聚簇索引和非聚簇索引两种，聚簇索引是按照数据存放的物理位置为顺序的，而非聚簇索引就不一样了；聚簇索引能提高多行检索的速度，而非聚簇索引对于单行的检索很快。</p><h6 id="主键索引："><a href="#主键索引：" class="headerlink" title="主键索引："></a><strong>主键索引</strong>：</h6><p>primary key    数据库表经常有一列或列组合，其值唯一标识表中的每一行，该列称为表的主键。   在数据库关系图中为表定义主键将自动创建主键索引，主键索引是唯一索引的特定类型。该索引要求主键中的每个值都唯一。当在查询中使用主键索引时，它还允许对数据的快速访问。 </p><h6 id="唯一索引："><a href="#唯一索引：" class="headerlink" title="唯一索引："></a><strong>唯一索引</strong>：</h6><p>UNIQUE   表明此索引的每一个索引值只对应唯一的数据记录，对于单列惟一性索引，这保证单列不包含重复的值。</p><h6 id="普通索引："><a href="#普通索引：" class="headerlink" title="普通索引："></a><strong>普通索引：</strong></h6><p>这是最基本的索引，它没有任何限制，比如上文中为title字段创建的索引就是一个普通索引，MyIASM中默认的BTREE类型的索引，也是我们大多数情况下用到的索引。</p><h6 id="全文索引"><a href="#全文索引" class="headerlink" title="全文索引"></a><strong>全文索引</strong></h6><p>FULLTEXT    索引仅可用于 MyISAM 表；他们可以从CHAR、VARCHAR或TEXT列中作为CREATE TABLE语句的一部分被创建，或是随后使用ALTER TABLE 或CREATE INDEX被添加。对于较大的数据集，将你的资料输入一个没有FULLTEXT索引的表中，然后创建索引，其速度比把资料输入现有FULLTEXT索引的速度更为快。不过切记对于大容量的数据表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法。</p><h6 id="组合索引"><a href="#组合索引" class="headerlink" title="组合索引"></a><strong>组合索引</strong></h6><p>平时用的SQL查询语句一般都有比较多的限制条件，所以为了进一步榨取MySQL的效率，就要考虑建立组合索引。例如上表中针对title和time建立一个组合索引：ALTER TABLE article ADD INDEX index_titme_time (title(50),time(10))。建立这样的组合索引，其实是相当于分别建立了下面两组组合索引：</p><h4 id="MySQL的数据结构"><a href="#MySQL的数据结构" class="headerlink" title="MySQL的数据结构"></a><strong>MySQL的数据结构</strong></h4><h5 id="B树"><a href="#B树" class="headerlink" title="B树"></a><strong>B树</strong></h5><p>B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B-树为系统最优化<strong>大块数据的读和写操作</strong>。B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在<strong>数据库</strong>和<strong>文件系统</strong>。</p><p><strong>B 树</strong>可以看作是对2-3查找树的一种扩展，即他允许每个节点有M-1个子节点。</p><ul><li>根节点至少有两个子节点</li><li>每个节点有M-1个key，并且以升序排列</li><li>位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间</li><li>其它节点至少有M/2个子节点</li><li>B Tree(B-):2-3树，每个节点上最多保留3个关键码，超过三个则取从小到大第2个位置的关键码，口诀取2留3</li></ul><p>下图是一个M=4 阶的B树:</p><p><img src="/images/MySQL优化/1.png" alt=""></p><p>可以看到B树是2-3树的一种扩展，他允许一个节点有多于2个的元素。</p><p>B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入</p><p><strong>6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4</strong>     的演示动画：</p><p><img src="/images/MySQL优化/2.gif" alt=""></p><h5 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a><strong>B+树</strong></h5><p>​    我们经常听到B+树就是这个概念，用这个树的目的和红黑树差不多，也是为了尽量保持树的平衡，当然红黑树是二叉树，但B+树就不是二叉树了，节点下面可以有多个子节点，数据库开发商会设置子节点数的一个最大值，这个值不会太小，所以B+树一般来说比较矮胖，而红黑树就比较瘦高了。<br>关于B+树的插入，删除，会涉及到一些算法以保持树的平衡，这里就不详述了。ORACLE的默认索引就是这种结构的。<br>如果经常需要同时对两个字段进行AND查询,那么使用两个单独索引不如建立一个复合索引，因为两个单独索引通常数据库只能使用其中一个，而使用复合索引因为索引本身就对应到两个字段上的，效率会有很大提高。</p><p><strong>B+</strong>树是对B树的一种变形树，它与B树的差异在于：</p><ul><li>有k个子结点的结点必然有k个关键码；</li><li>非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。</li><li>树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。</li></ul><p>如下图，是一个B+树:</p><p><img src="/images/MySQL优化/3.png" alt=""></p><p><img src="/images/MySQL优化/4.gif" alt=""></p><h3 id="3、分表分库技术"><a href="#3、分表分库技术" class="headerlink" title="3、分表分库技术"></a>3、<strong>分表分库技术</strong></h3><p>取模分表、水平分割、垂直分割</p><h4 id="什么是分库分表？"><a href="#什么是分库分表？" class="headerlink" title="什么是分库分表？"></a><strong>什么是分库分表</strong>？</h4><p>顾名思义，分库分表就是按照一定的规则，对原有的数据库和表进行拆分，把原本存储于一个库的数据分块存储到多个库上，把原本存储于一个表的数据分块存储到多个表上。</p><h4 id="为什么要分库分表？"><a href="#为什么要分库分表？" class="headerlink" title="为什么要分库分表？"></a><strong>为什么要分库分表</strong>？</h4><p>随着时间和业务的发展，数据库中的数据量增长是不可控的，库和表中的数据会越来越大，随之带来的是更高的磁盘、IO、系统开销，甚至性能上的瓶颈，而一台服务的资源终究是有限的，因此需要对数据库和表进行拆分，从而更好的提供数据服务。</p><p>可以用说用到MySQL的地方,只要数据量一大, 马上就会遇到一个问题,要分库分表. 这里引用一个问题为什么要分库分表呢?MySQL处理不了大的表吗? 其实是可以处理的大表的.我所经历的项目中单表物理上文件大小在80G多,单表记录数在5亿以上,而且这个表 属于一个非常核用的表:朋友关系表. </p><p>但这种方式可以说不是一个最佳方式. 因为面临文件系统如Ext3文件系统对大于大文件处理上也有许多问题. 这个层面可以用xfs文件系统进行替换.但MySQL单表太大后有一个问题是不好解决: 表结构调整相关的操作基<br>本不在可能.所以大项在使用中都会面监着分库分表的应用. </p><p>从Innodb本身来讲数据文件的Btree上只有两个锁, 叶子节点锁和子节点锁,可以想而知道,当发生页拆分或是添加新叶时都会造成表里不能写入数据.所以分库分表还就是一个比较好的选择了. </p><h4 id="怎么分库分表合适呢"><a href="#怎么分库分表合适呢" class="headerlink" title="怎么分库分表合适呢?"></a><strong>怎么分库分表合适呢</strong>?</h4><p>经测试在单表1000万条记录一下,写入读取性能是比较好的. 这样在留点buffer,那么单表全是数据字型的保持在800万条记录以下, 有字符型的单表保持在500万以下. </p><p>如果按 100库100表来规划,如用户业务: 500万<em>100</em>100 = 50000000万 = 5000亿记录. </p><p>心里有一个数了,按业务做规划还是比较容易的.</p><p>分布式数据库架构–排序、分页、分组、实现</p><h4 id="什么时候分库？"><a href="#什么时候分库？" class="headerlink" title="什么时候分库？"></a><strong>什么时候分库</strong>？</h4><p>电商项目将一个项目进行拆分，拆成多个小项目，每个小项目都有自己单独的数据库，互不影响（垂直分割订单数据库）</p><h4 id="什么时候分表？"><a href="#什么时候分表？" class="headerlink" title="什么时候分表？"></a><strong>什么时候分表</strong>？</h4><p>对于某网站平台的数据库表-公司表，数据量很大，这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。</p><h4 id="为什么分表？"><a href="#为什么分表？" class="headerlink" title="为什么分表？"></a><strong>为什么分表</strong>？</h4><p>当一张表的数据达到几千万时，你查询一次所花的时间会变多，如果有联合查询的话，我想有可能会死在那儿了。分表的目的就在于此，减小数据库的负担，缩短查询时间。</p><p>某网站现在的数据量至多是5000万条，可以设计每张表容纳的数据量是500万条，也就是拆分成10张表，</p><p>那么如何判断某张表的数据是否容量已满呢？可以在程序段对于要新增数据的表，在插入前先做统计表记录数量的操作，当&lt;500万条数据，就直接插入，当已经到达阀值，可以在程序段新创建数据库表（或者已经事先创建好），再执行插入操作。</p><h5 id="垂直分库-分表"><a href="#垂直分库-分表" class="headerlink" title="垂直分库/分表"></a><strong>垂直分库</strong>/分表</h5><p>如果把业务切割得足够独立，那把不同业务的数据放到不同的数据库服务器将是一个不错的方案，而且万一其中一个业务崩溃了也不会影响其他业务的正常进行，并且也起到了负载分流的作用，大大提升了数据库的吞吐能力。经过垂直分区后的数据库架构图如下：</p><p><img src="/images/MySQL优化/5.jpg" alt=""></p><p>然而，尽管业务之间已经足够独立了，但是有些业务之间或多或少总会有点联系，如用户，基本上都会和每个业务相关联，况且这种分区方式，也不能解决单张表数据量暴涨的问题，因此可以尝试水平分割</p><h6 id="优点：-1"><a href="#优点：-1" class="headerlink" title="优点："></a><strong>优点：</strong></h6><ol><li>拆分后业务清晰，达到专库专用。</li><li>可以实现热数据和冷数据的分离，将不经常变化的数据和变动较大的数据分散再不同的库/表中。</li><li>便于维护</li></ol><h6 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a><strong>缺点：</strong></h6><ol><li>不解决数据量大带来的性能损耗，读写压力依旧很大</li><li>不同的业务无法跨库关联（join），只能通过业务来关联</li></ol><h5 id="水平分库-分表"><a href="#水平分库-分表" class="headerlink" title="水平分库/分表"></a><strong>水平分库/分表</strong></h5><p>这是一个非常好的思路，将用户按一定规则（按id哈希）分组，并把该组用户的数据存储到一个数据库分片中，即一个sharding，这样随着用户数量的增加，只要简单地配置一台服务器即可，原理图如下：</p><p><img src="/images/MySQL优化/6.jpg" alt=""></p><p>如何来确定某个用户所在的shard呢，可以建一张用户和shard对应的数据表，每次请求先从这张表找用户的shard id，再从对应shard中查询相关数据，如下图所示：</p><p><img src="/images/MySQL优化/7.jpg" alt=""></p><h6 id="优点：-2"><a href="#优点：-2" class="headerlink" title="优点："></a><strong>优点：</strong></h6><ol><li>单库（表）的数据量得以减少，提高性能</li><li>提高了系统的稳定性和负载能力</li><li>切分出的表结构相同，程序改动较少</li></ol><h6 id="缺点：-2"><a href="#缺点：-2" class="headerlink" title="缺点："></a><strong>缺点：</strong></h6><ol><li>拆分规则较难抽象</li><li>数据分片在扩容时需要迁移</li><li>维护量增大</li><li>依然存在跨库无法join等问题，同时涉及分布式事务，数据一致性等问题。</li></ol><h4 id="分库-分表分类"><a href="#分库-分表分类" class="headerlink" title="分库/分表分类"></a><strong>分库/分表分类</strong></h4><h5 id="单库单表"><a href="#单库单表" class="headerlink" title="单库单表"></a><strong>单库单表</strong></h5><p>单库单表是最常见的数据库设计，例如，有一张用户(user)表放在数据库db中，所有的用户都可以在db库中的user表中查到。 </p><h5 id="单库多表"><a href="#单库多表" class="headerlink" title="单库多表"></a><strong>单库多表</strong></h5><p>随着用户数量的增加，user表的数据量会越来越大，当数据量达到一定程度的时候对user表的查询会渐渐的变慢，从而影响整个DB的性能。如果使用mysql, 还有一个更严重的问题是，当需要添加一列的时候，mysql会锁表，期间所有的读写操作只能等待。 </p><p>可以通过某种方式将user进行水平的切分，产生两个表结构完全一样的user_0000,user_0001等表，user_0000 + user_0001 + …的数据刚好是一份完整的数据。 </p><h5 id="多库多表"><a href="#多库多表" class="headerlink" title="多库多表"></a><strong>多库多表</strong></h5><p>随着数据量增加也许单台DB的存储空间不够，随着查询量的增加单台数据库服务器已经没办法支撑。这个时候可以再对数据库进行水平区分。 </p><h4 id="分库分表规则"><a href="#分库分表规则" class="headerlink" title="分库分表规则"></a><strong>分库分表规则</strong></h4><p> 设计表的时候需要确定此表按照什么样的规则进行分库分表。例如，当有新用户时，程序得确定将此用户信息添加到哪个表中；同理，当登录的时候我们得通过用户的账号找到数据库中对应的记录，所有的这些都需要按照某一规则进行。<br>路由 </p><p>通过分库分表规则查找到对应的表和库的过程。如分库分表的规则是user_id mod 4的方式，当用户新注册了一个账号，账号id的123,我们可以通过id mod 4的方式确定此账号应该保存到User_0003表中。当用户123登录的时候，我们通过123 mod 4后确定记录在User_0003中。 </p><h4 id="分库分表产生的问题，及注意事项"><a href="#分库分表产生的问题，及注意事项" class="headerlink" title="分库分表产生的问题，及注意事项"></a><strong>分库分表产生的问题，及注意事项</strong></h4><h5 id="分库分表维度的问题"><a href="#分库分表维度的问题" class="headerlink" title="分库分表维度的问题"></a><strong>分库分表维度的问题</strong></h5><p>假如用户购买了商品,需要将交易记录保存取来，如果按照用户的纬度分表，则每个用户的交易记录都保存在同一表中，所以很快很方便的查找到某用户的 购买情况，但是某商品被购买的情况则很有可能分布在多张表中，查找起来比较麻烦。反之，按照商品维度分表，可以很方便的查找到此商品的购买情况，但要查找 到买人的交易记录比较麻烦。 </p><p>所以常见的解决方式有： </p><ul><li>通过扫表的方式解决，此方法基本不可能，效率太低了。</li><li>记录两份数据，一份按照用户纬度分表，一份按照商品维度分表。</li><li>通过搜索引擎解决，但如果实时性要求很高，又得关系到实时搜索。 </li></ul><h5 id="联合查询的问题"><a href="#联合查询的问题" class="headerlink" title="联合查询的问题"></a><strong>联合查询的问题</strong></h5><p>联合查询基本不可能，因为关联的表有可能不在同一数据库中。 </p><h5 id="避免跨库事务"><a href="#避免跨库事务" class="headerlink" title="避免跨库事务"></a><strong>避免跨库事务</strong></h5><p>避免在一个事务中修改db0中的表的时候同时修改db1中的表，一个是操作起来更复杂，效率也会有一定影响。 </p><h5 id="尽量把同一组数据放到同一DB服务器上"><a href="#尽量把同一组数据放到同一DB服务器上" class="headerlink" title="尽量把同一组数据放到同一DB服务器上"></a><strong>尽量把同一组数据放到同一</strong>DB服务器上</h5><p>例如将卖家a的商品和交易信息都放到db0中，当db1挂了的时候，卖家a相关的东西可以正常使用。也就是说避免数据库中的数据依赖另一数据库中的数据。 </p><h5 id="一主多备"><a href="#一主多备" class="headerlink" title="一主多备"></a><strong>一主多备</strong></h5><p>在实际的应用中，绝大部分情况都是读远大于写。Mysql提供了读写分离的机制，所有的写操作都必须对应到Master，读操作可以在 Master和Slave机器上进行，Slave与Master的结构完全一样，一个Master可以有多个Slave,甚至Slave下还可以挂 Slave,通过此方式可以有效的提高DB集群的 QPS.                                                       </p><p>所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。<br>此外，可以看出Master是集群的瓶颈，当写操作过多，会严重影响到Master的稳定性，如果Master挂掉，整个集群都将不能正常工作。<br>所以</p><ul><li>当读压力很大的时候，可以考虑添加Slave机器的分式解决，但是当Slave机器达到一定的数量就得考虑分库了。</li><li>当写压力很大的时候，就必须得进行分库操作。 </li></ul><h3 id="4、读写分离"><a href="#4、读写分离" class="headerlink" title="4、读写分离"></a><strong>4、读写分离</strong></h3><p>MySQL的主从复制解决了数据库的读写分离，并很好的提升了读的性能</p><p><img src="/images/MySQL优化/8.jpg" alt=""></p><p>其主从复制的过程如下图所示：</p><p><img src="/images/MySQL优化/9.jpg" alt=""></p><p>主从复制也带来其他一系列性能瓶颈问题：</p><ol><li>写入无法扩展</li><li>写入无法缓存</li><li>复制延时</li><li>锁表率上升</li><li>表变大，缓存率下降</li></ol><h5 id="使用Sharding-JDBC进行分库分表"><a href="#使用Sharding-JDBC进行分库分表" class="headerlink" title="使用Sharding-JDBC进行分库分表"></a><strong>使用Sharding-JDBC进行分库分表</strong></h5><h6 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h6><p>Sharding-JDBC是一个开源的分布式数据库中间件，它无需额外部署和依赖，完全兼容JDBC和各种ORM框架。Sharding-JDBC作为面向开发的微服务云原生基础类库，完整的实现了分库分表、读写分离和分布式主键功能，并初步实现了柔性事务。关于sj的详细配置和使用方法请参见<a href="https://link.jianshu.com?t=http%3A%2F%2Fshardingsphere.io%2Fdocs_cn%2F00-overview%2F" target="_blank" rel="noopener">官方文档</a></p><h6 id="配置"><a href="#配置" class="headerlink" title="配置"></a><strong>配置</strong></h6><p>Sharing-JDBC的springboot starter对springboot 2.0还不支持。我也是配置完项目启动失败才发现这个issue，懒得切换版本就暂且不使用starter pom吧，直接使用编程式配置。</p><h6 id="准备"><a href="#准备" class="headerlink" title="准备"></a><strong>准备</strong></h6><p>本Demo中使用的两个数据源是db0和db1，每个数据源之中包含了两组表t_order_0和t_order_1，t_order_item_0和t_order_item_1 。和官方文档的demo一致，这两组表的建表语句为：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_order_x (</span><br><span class="line">  order_id <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  user_id  <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (order_id)</span><br><span class="line">);</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> t_order_item_x (</span><br><span class="line">  item_id  <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  order_id <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  user_id  <span class="built_in">INT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (item_id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>逻辑结构如下：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">db0</span><br><span class="line">  ├── t_order_0 </span><br><span class="line">  └── t_order_1 </span><br><span class="line">db1</span><br><span class="line">  ├── t_order_0 </span><br><span class="line">  └── t_order_1</span><br></pre></td></tr></table></figure><p>首先引入依赖</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">       &lt;groupId&gt;io.shardingjdbc&lt;/groupId&gt;</span><br><span class="line">       &lt;artifactId&gt;sharding-jdbc-core&lt;/artifactId&gt;</span><br><span class="line">       &lt;version&gt;2.0.3&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p>配置表分片策略</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Bean</span></span><br><span class="line">   <span class="function">TableRuleConfiguration <span class="title">getOrderTableRuleConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       TableRuleConfiguration orderTableRuleConfig = <span class="keyword">new</span> TableRuleConfiguration();</span><br><span class="line">       <span class="comment">//配置逻辑表名，并非数据库中真实存在的表名，而是sql中使用的那个，不受分片策略而改变.  </span></span><br><span class="line">       <span class="comment">//例如：select * frpm t_order where user_id = xxx</span></span><br><span class="line">       orderTableRuleConfig.setLogicTable(<span class="string">"t_order"</span>);</span><br><span class="line">       <span class="comment">//配置真实的数据节点，即数据库中真实存在的节点，由数据源名 + 表名组成</span></span><br><span class="line">       <span class="comment">//$&#123;&#125; 是一个groovy表达式，[]表示枚举，&#123;...&#125;表示一个范围。  </span></span><br><span class="line">       <span class="comment">//整个inline表达式最终会是一个笛卡尔积，表示ds_0.t_order_0. ds_0.t_order_1</span></span><br><span class="line">       <span class="comment">// ds_1.t_order_0. ds_1.t_order_0</span></span><br><span class="line">       orderTableRuleConfig.setActualDataNodes(<span class="string">"ds_$&#123;0..1&#125;.t_order_$&#123;0..1&#125;"</span>);</span><br><span class="line">       <span class="comment">//主键生成列，默认的主键生成算法是snowflake</span></span><br><span class="line">       orderTableRuleConfig.setKeyGeneratorColumnName(<span class="string">"order_id"</span>);</span><br><span class="line">      <span class="comment">//设置分片策略，这里简单起见直接取模，也可以使用自定义算法来实现分片规则</span></span><br><span class="line">       orderTableRuleConfig.setTableShardingStrategyConfig(<span class="keyword">new</span> InlineShardingStrategyConfiguration(<span class="string">"order_id"</span>,<span class="string">"t_order_$&#123;order_id % 2&#125;"</span>));</span><br><span class="line">       <span class="keyword">return</span> orderTableRuleConfig;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Bean</span></span><br><span class="line">   <span class="function">TableRuleConfiguration <span class="title">getOrderItemTableRuleConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       TableRuleConfiguration orderItemTableRuleConfig = <span class="keyword">new</span> TableRuleConfiguration();</span><br><span class="line">       orderItemTableRuleConfig.setLogicTable(<span class="string">"t_order_item"</span>);</span><br><span class="line">       orderItemTableRuleConfig.setActualDataNodes(<span class="string">"ds_$&#123;0..1&#125;.t_order_item_$&#123;0..1&#125;"</span>);</span><br><span class="line">       orderItemTableRuleConfig.setTableShardingStrategyConfig(<span class="keyword">new</span> InlineShardingStrategyConfiguration(<span class="string">"order_item_id"</span>,<span class="string">"t_order_item_$&#123;order_id % 2&#125;"</span>));</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> orderItemTableRuleConfig;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>配置数据源</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Map&lt;String, DataSource&gt; <span class="title">createDataSourceMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      Map&lt;String, DataSource&gt; result = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">2</span>, <span class="number">1</span>);</span><br><span class="line">      result.put(<span class="string">"ds_0"</span>, createDataSource(<span class="string">"ds_0"</span>));</span><br><span class="line">      result.put(<span class="string">"ds_1"</span>, createDataSource(<span class="string">"ds_1"</span>));</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> DataSource <span class="title">createDataSource</span><span class="params">(<span class="keyword">final</span> String dataSourceName)</span> </span>&#123;</span><br><span class="line">      DruidDataSource result = <span class="keyword">new</span> DruidDataSource();</span><br><span class="line">      result.setInitialSize(<span class="number">10</span>);</span><br><span class="line">      result.setMinIdle(<span class="number">10</span>);</span><br><span class="line">      result.setMaxActive(<span class="number">50</span>);</span><br><span class="line">      result.setDriverClassName(com.mysql.jdbc.Driver.class.getName());</span><br><span class="line">      result.setUrl(String.format(<span class="string">"jdbc:mysql://localhost:3306/%s?useSSL=false"</span>, dataSourceName));</span><br><span class="line">      result.setUsername(<span class="string">"root"</span>);</span><br><span class="line">      result.setPassword(<span class="string">""</span>);</span><br><span class="line">      <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="meta">@Bean</span></span><br><span class="line">  <span class="function">DataSource <span class="title">getShardingDataSource</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">      ShardingRuleConfiguration shardingRuleConfig = <span class="keyword">new</span> ShardingRuleConfiguration();</span><br><span class="line">      shardingRuleConfig.getTableRuleConfigs().add(getOrderTableRuleConfiguration());</span><br><span class="line">      shardingRuleConfig.getTableRuleConfigs().add(getOrderItemTableRuleConfiguration());</span><br><span class="line">      shardingRuleConfig.getBindingTableGroups().add(<span class="string">"t_order, t_order_item"</span>);</span><br><span class="line">      shardingRuleConfig.setDefaultDatabaseShardingStrategyConfig(  </span><br><span class="line">      <span class="keyword">new</span> InlineShardingStrategyConfiguration(<span class="string">"user_id"</span>, <span class="string">"ds_$&#123;user_id % 2&#125;"</span>));</span><br><span class="line">      shardingRuleConfig.setDefaultTableShardingStrategyConfig(  </span><br><span class="line">      <span class="keyword">new</span> InlineShardingStrategyConfiguration(<span class="string">"order_id"</span>, <span class="string">"t_order_$&#123;order_id % 2&#125;"</span>));</span><br><span class="line">      <span class="keyword">return</span> ShardingDataSourceFactory.createDataSource(createDataSourceMap(),  </span><br><span class="line">      shardingRuleConfig, <span class="keyword">new</span> HashMap&lt;&gt;(), <span class="keyword">null</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h6 id="结果"><a href="#结果" class="headerlink" title="结果"></a><strong>结果</strong></h6><p>使用junittest插入一条记录，查看分片结果：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootTest</span></span><br><span class="line"><span class="meta">@RunWith</span>(SpringRunner.class)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderDaoTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span> <span class="keyword">private</span> OrderDao orderDao;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Order order = <span class="keyword">new</span> Order();</span><br><span class="line">        order.setUserId(<span class="number">1</span>);</span><br><span class="line">        order.setOrderId(<span class="number">1</span>);</span><br><span class="line">        <span class="comment">//insert into t_order (order_id, user_id) values(#&#123;orderId&#125;, #&#123;userId&#125;)</span></span><br><span class="line">        orderDao.addOrder(order);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>t_order这张表配置的分片策略是按照order_id与2取模，分库策略则是按照user_id与2取模，<br>所以最终的结果应该是插入在ds_1中的t_order_1中。</p><h3 id="5、存储过程"><a href="#5、存储过程" class="headerlink" title="5、存储过程"></a><strong>5、存储过程</strong></h3><h4 id="介绍："><a href="#介绍：" class="headerlink" title="介绍："></a><strong>介绍：</strong></h4><p>就是一组SQL语句集，功能强大，可以实现一些比较复杂的逻辑功能，类似于JAVA语言中的方法；</p><h4 id="优点：-3"><a href="#优点：-3" class="headerlink" title="优点："></a><strong>优点</strong>：</h4><p>①、使用了存过程，很多相似性的删除，更新，新增等操作就变得轻松了，并且以后也便于管理！<br>②、存储过程因为SQL语句已经预编绎过了，因此运行的速度比较快。<br>③、存储过程可以接受参数、输出参数、返回单个或多个结果集以及返回值。可以向程序返回错误原因。<br>④、存储过程运行比较稳定，不会有太多的错误。只要一次成功，以后都会按这个程序运行。<br>⑤、存储过程主要是在服务器上运行，减少对客户机的压力。<br>⑥、存储过程可以包含程序流、逻辑以及对数据库的查询。同时可以实体封装和隐藏了数据逻辑。<br>⑦、存储过程可以在单个存储过程中执行一系列SQL语句。<br>⑧、存储过程可以从自己的存储过程内引用其它存储过程，这可以简化一系列复杂语句。</p><h3 id="6、配置MySQL最大连接数（my-ini配置）"><a href="#6、配置MySQL最大连接数（my-ini配置）" class="headerlink" title="6、配置MySQL最大连接数（my.ini配置）"></a><strong>6、配置MySQL最大连接数（my.ini配置）</strong></h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--查看最大连接数</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">variables</span> <span class="keyword">like</span> <span class="string">'%max_connections%'</span>;</span><br><span class="line"><span class="comment">--修改最大连接数</span></span><br><span class="line"><span class="keyword">set</span> <span class="keyword">GLOBAL</span> max_connections = <span class="number">200</span>;</span><br></pre></td></tr></table></figure><h3 id="8、随时清理碎片"><a href="#8、随时清理碎片" class="headerlink" title="8、随时清理碎片"></a><strong>8、随时清理碎片</strong></h3><h4 id="产生的原因？"><a href="#产生的原因？" class="headerlink" title="产生的原因？"></a><strong>产生的原因？</strong></h4><p>①、表的存储会出现碎片化，每当删除了一行内容，该段空间就会变为空白、被留空，而在一段时间内的大量删除操作，会使这种留空的空间变得比存储列表内容所使用的空间更大；</p><p>②、当执行插入操作时，MySQL会尝试使用空白空间，但如果某个空白空间一直没有被大小合适的数据占用，仍然无法将其彻底占用，就形成了碎片；</p><p>③、当MySQL对数据进行扫描时，它扫描的对象实际是列表的容量需求上限，也就是数据被写入的区域中处于峰值位置的部分；</p><h4 id="如何处理？"><a href="#如何处理？" class="headerlink" title="如何处理？"></a><strong>如何处理？</strong></h4><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">--查看表的碎片大小</span></span><br><span class="line"><span class="keyword">SHOW</span> <span class="keyword">TABLE</span> <span class="keyword">STATUS</span> <span class="keyword">LIKE</span> <span class="string">'表名'</span>;</span><br><span class="line"><span class="comment">--清除表的碎片（MyISAM）</span></span><br><span class="line"><span class="keyword">OPTIMIZE</span> <span class="keyword">TABLE</span> table_name；</span><br><span class="line"><span class="comment">--清除表的碎片（InnoDB）</span></span><br><span class="line"> <span class="keyword">alter</span> <span class="keyword">table</span> 表名 <span class="keyword">engine</span>=<span class="keyword">InnoDB</span></span><br></pre></td></tr></table></figure><h3 id="9、SQL语句优化"><a href="#9、SQL语句优化" class="headerlink" title="9、SQL语句优化"></a><strong>9、SQL语句优化</strong></h3><h4 id="关键词的执行顺序"><a href="#关键词的执行顺序" class="headerlink" title="关键词的执行顺序"></a><strong>关键词的执行顺序</strong></h4><p><strong>写的顺序：</strong>select … from… where…. group by… having… order by.. limit [offset,]<br><strong>执行顺序：</strong>from… where…group by… having…. select … order by… limit</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">下面具体分析一下查询处理的每一个阶段</span><br><span class="line">1 FROM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1</span><br><span class="line">2 ON: 对虚表VT1进行ON筛选，只有那些符合&lt;join-condition&gt;的行才会被记录在虚表VT2中。</span><br><span class="line">3 JOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3, rug from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结   果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。</span><br><span class="line">4 WHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合&lt;<span class="built_in">where</span>-condition&gt;的记录才会被插入到虚拟表VT4中。</span><br><span class="line">5 GROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5.</span><br><span class="line">6 CUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6.</span><br><span class="line">7 HAVING： 对虚拟表VT6应用having过滤，只有符合&lt;having-condition&gt;的记录才会被 插入到虚拟表VT7中。</span><br><span class="line">8 SELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。</span><br><span class="line">9 DISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9.</span><br><span class="line">10 ORDER BY: 将虚拟表VT9中的记录按照&lt;order_by_list&gt;进行排序操作，产生虚拟表VT10.</span><br><span class="line">11 LIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。</span><br></pre></td></tr></table></figure><p><strong>详细见SQL语句优化文档</strong></p><h3 id="10、执行计划"><a href="#10、执行计划" class="headerlink" title="10、执行计划"></a>10、执行计划</h3><h4 id="定位慢查询"><a href="#定位慢查询" class="headerlink" title="定位慢查询"></a><strong>定位慢查询</strong></h4><h5 id="什么是慢查询？"><a href="#什么是慢查询？" class="headerlink" title="什么是慢查询？"></a><strong>什么是慢查询？</strong></h5><p>mysql默认sql语句在10S内没有返回，则被认为是慢查询</p><p>慢查询都有日志记录</p><p>使用show status查看mysql服务器状态信息</p><h5 id="命令："><a href="#命令：" class="headerlink" title="命令："></a><strong>命令：</strong></h5><p>查看数据库启动时间：show status like ‘uptime’;</p><p>显示数据可的查询、更新、添加、删除的次数：show status like ‘com_select’,……</p><p>显示数据库的连接数：show status like ‘connections’;</p><p>显示慢查询次数：show status like ‘slow_queries’;</p><p>默认情况mysql不会记录慢查询的日志</p><p> 步骤：停止mysql服务-&gt;进入mysql目录-&gt;进入cmd-&gt;输入 mysqld.exe –safe-mode –slow-query-log-&gt;不要关闭cmd界面</p><p>查看慢查询log日志：在mysql data目录中找log文件（可以在my.ini中找到目录位置）</p><h4 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a><strong>索引优化</strong></h4><h5 id="①、何时使用聚集索引或非聚集索引？"><a href="#①、何时使用聚集索引或非聚集索引？" class="headerlink" title="①、何时使用聚集索引或非聚集索引？"></a><strong>①、何时使用聚集索引或非聚集索引？</strong></h5><table><thead><tr><th>动作描述</th><th>使用聚集索引</th><th>使用非聚集索引</th></tr></thead><tbody><tr><td>列经常被分组排序</td><td>使用</td><td>使用</td></tr><tr><td>返回某范围内的数据</td><td>使用</td><td>不使用</td></tr><tr><td>一个或极少不同值</td><td>不使用</td><td>不使用</td></tr><tr><td>小数目的不同值</td><td>使用</td><td>不使用</td></tr><tr><td>大数目的不同值</td><td>不使用</td><td>使用</td></tr><tr><td>频繁更新的列</td><td>不使用</td><td>使用</td></tr><tr><td>外键列</td><td>使用</td><td>使用</td></tr><tr><td>主键列</td><td>使用</td><td>使用</td></tr><tr><td>频繁修改索引列</td><td>不使用</td><td>使用</td></tr></tbody></table><h5 id="②、-索引不会包含有NULL值的列"><a href="#②、-索引不会包含有NULL值的列" class="headerlink" title="②、 索引不会包含有NULL值的列"></a><strong>②、 索引不会包含有NULL值的列</strong></h5><p>只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为NULL。</p><h5 id="③、使用短索引"><a href="#③、使用短索引" class="headerlink" title="③、使用短索引"></a><strong>③、使用短索引</strong></h5><p>对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。</p><h5 id="④、-索引列排序"><a href="#④、-索引列排序" class="headerlink" title="④、 索引列排序"></a><strong>④、 索引列排序</strong></h5><p>MySQL查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。</p><h5 id="⑤、-like语句操作"><a href="#⑤、-like语句操作" class="headerlink" title="⑤、 like语句操作"></a><strong>⑤、 like语句操作</strong></h5><p>一般情况下不鼓励使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。</p><h5 id="⑥、-不要在列上进行运算"><a href="#⑥、-不要在列上进行运算" class="headerlink" title="⑥、 不要在列上进行运算"></a><strong>⑥、 不要在列上进行运算</strong></h5><p>例如：select <em> from users where YEAR(adddate)&lt;2007，将在每个行上进行运算，这将导致索引失效而进行全表扫描，因此我们可以改成：select </em> from users where adddate&lt;’2007-01-01′。</p><h3 id="11、硬件优化"><a href="#11、硬件优化" class="headerlink" title="11、硬件优化"></a><strong>11、硬件优化</strong></h3><p><img src="/images/MySQL优化/10.gif" alt=""></p><h4 id="从图上可以看到基本上每种设备都有两个指标："><a href="#从图上可以看到基本上每种设备都有两个指标：" class="headerlink" title="从图上可以看到基本上每种设备都有两个指标："></a><strong>从图上可以看到基本上每种设备都有两个指标：</strong></h4><p>延时（响应时间）：表示硬件的突发处理能力；</p><p>带宽（吞吐量）：代表硬件持续处理能力。</p><h4 id="从上图可以看出，计算机系统硬件性能从高到代依次为："><a href="#从上图可以看出，计算机系统硬件性能从高到代依次为：" class="headerlink" title="从上图可以看出，计算机系统硬件性能从高到代依次为："></a><strong>从上图可以看出，计算机系统硬件性能从高到代依次为：</strong></h4><p>CPU——Cache(L1-L2-L3)——内存——SSD硬盘——网络——硬盘</p><p>由于SSD硬盘还处于快速发展阶段，所以本文的内容不涉及SSD相关应用系统。</p><h4 id="根据数据库知识，我们可以列出每种硬件主要的工作内容："><a href="#根据数据库知识，我们可以列出每种硬件主要的工作内容：" class="headerlink" title="根据数据库知识，我们可以列出每种硬件主要的工作内容："></a><strong>根据数据库知识，我们可以列出每种硬件主要的工作内容：</strong></h4><p>CPU及内存：缓存数据访问、比较、排序、事务检测、SQL解析、函数或逻辑运算；</p><p>网络：结果数据传输、SQL请求、远程数据库访问（dblink）；</p><p>硬盘：数据访问、数据写入、日志记录、<a href="http://lib.csdn.net/base/hadoop" target="_blank" rel="noopener">大数据</a>量排序、大表连接。</p><h4 id="性能基本优化法则："><a href="#性能基本优化法则：" class="headerlink" title="性能基本优化法则："></a><strong>性能基本优化法则：</strong></h4><p><img src="/images/MySQL优化/11.gif" alt=""></p><p><strong>优化法则归纳为5个层次：</strong></p><p>1、  减少数据访问（减少磁盘访问）</p><p>2、  返回更少数据（减少网络传输或磁盘访问）</p><p>3、  减少交互次数（减少网络传输）</p><p>4、  减少服务器CPU开销（减少CPU及内存开销）</p><p>5、  利用更多资源（增加资源）</p><p> 由于每一层优化法则都是解决其对应硬件的性能问题，所以带来的性能提升比例也不一样。传统数据库系统设计是也是尽可能对低速设备提供优化方法，因此针对低速设备问题的可优化手段也更多，优化成本也更低。我们任何一个SQL的性能优化都应该按这个规则由上到下来诊断问题并提出解决方案，而不应该首先想到的是增加资源解决问题。</p><h4 id="以下是每个优化法则层级对应优化效果及成本经验参考："><a href="#以下是每个优化法则层级对应优化效果及成本经验参考：" class="headerlink" title="以下是每个优化法则层级对应优化效果及成本经验参考："></a><strong>以下是每个优化法则层级对应优化效果及成本经验参考：</strong></h4><table><thead><tr><th><strong>优化法则</strong></th><th><strong>性能提升效果</strong></th><th><strong>优化成本</strong></th></tr></thead><tbody><tr><td>减少数据访问</td><td>1~1000</td><td>低</td></tr><tr><td>返回更少数据</td><td>1~100</td><td>低</td></tr><tr><td>减少交互次数</td><td>1~20</td><td>低</td></tr><tr><td>减少服务器CPU开销</td><td>1~5</td><td>低</td></tr><tr><td>利用更多资源</td><td>@~10</td><td>高</td></tr></tbody></table><h3 id="参考："><a href="#参考：" class="headerlink" title="参考："></a><strong>参考：</strong></h3><p>分库/分表实现参考：<a href="https://www.jianshu.com/u/138209947f2b" target="_blank" rel="noopener">codingBoyJack</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Trinity调度延迟解决方法</title>
      <link href="/2019/04/09/trinity-diao-du-yan-chi-jie-jue-fang-fa/"/>
      <url>/2019/04/09/trinity-diao-du-yan-chi-jie-jue-fang-fa/</url>
      
        <content type="html"><![CDATA[<h3 id="1、查询各表占用的空间"><a href="#1、查询各表占用的空间" class="headerlink" title="1、查询各表占用的空间"></a>1、查询各表占用的空间</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">   relname <span class="keyword">as</span> <span class="string">"Table"</span>,</span><br><span class="line">   pg_size_pretty(pg_total_relation_size(relid)) <span class="keyword">As</span> <span class="string">"Size"</span>,</span><br><span class="line">   pg_size_pretty(pg_total_relation_size(relid) - pg_relation_size(relid)) <span class="keyword">as</span> <span class="string">"External Size"</span></span><br><span class="line"><span class="keyword">FROM</span> pg_catalog.pg_statio_user_tables <span class="keyword">ORDER</span> <span class="keyword">BY</span> pg_total_relation_size(relid) <span class="keyword">DESC</span>;</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="2、需要维护的table"><a href="#2、需要维护的table" class="headerlink" title="2、需要维护的table"></a>2、需要维护的table</h3><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">task, taskdependencyrule, jobexecution, jobexecutionschedule, jobtxdate</span><br></pre></td></tr></table></figure><h3 id="3、执行vacuum操作"><a href="#3、执行vacuum操作" class="headerlink" title="3、执行vacuum操作"></a>3、执行vacuum操作</h3><p><img src="/images/Trinity_vacuum/1.jpg" alt=""></p><p>右键需要维护的table-&gt;选择Maintenance-&gt;ANALYZE-&gt;ok</p><p><img src="/images/Trinity_vacuum/2.jpg" alt=""></p><p>再选择Vacuum-&gt;选择full-&gt;ok-&gt;REINDEX-&gt;ok</p><p><img src="/images/Trinity_vacuum/3.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> Trinity </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ETL </tag>
            
            <tag> Trinity </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建HDP集群报OPEN SSL问题解决方法</title>
      <link href="/2019/03/27/open-ssl-bao-cuo/"/>
      <url>/2019/03/27/open-ssl-bao-cuo/</url>
      
        <content type="html"><![CDATA[<h3 id="报错："><a href="#报错：" class="headerlink" title="报错："></a>报错：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ERROR 2015-09-23 09:47:07,402 NetUtil.py:77 - [Errno 8] _ssl.c:492: EOF occurred in violation of protocol</span><br><span class="line">ERROR 2015-09-23 09:47:07,402 NetUtil.py:78 - SSLError: Failed to connect. Please check openssl library versions.</span><br><span class="line">Refer to: https://bugzilla.redhat.com/show_bug.cgi?id=1022468 for more details.</span><br><span class="line">WARNING 2015-09-23 09:47:07,402 NetUtil.py:105 - Server at https://test.org:8440is not reachable, sleeping for 10 seconds...</span><br><span class="line">WARNING 2015-09-23 09:47:07,402 NetUtil.py:105 - Server at https://test.org:8440is not reachable, sleeping for 10 seconds...</span><br><span class="line">INFO 2015-09-23 09:47:14,746 main.py:74 - loglevel=logging.INFO</span><br><span class="line">INFO 2015-09-23 09:47:14,746 main.py:74 - loglevel=logging.INFO</span><br><span class="line">INFO 2015-09-23 09:47:17,403 NetUtil.py:59 - Connecting to https://test.org:8440/ca</span><br><span class="line">WARNING 2015-09-23 09:47:17,404 NetUtil.py:82 - Failed to connect to https://test.org:8440/ca due to [Errno 111] Connection refused</span><br><span class="line">WARNING 2015-09-23 09:47:17,404 NetUtil.py:105 - Server at https://test.org:8440is not reachable, sleeping for 10 seconds...</span><br><span class="line">WARNING 2015-09-23 09:47:17,404 NetUtil.py:105 - Server at https://test.org:8440is not reachable, sleeping for 10 seconds...</span><br><span class="line">ERROR 2015-09-23 09:47:19,780 main.py:315 - Fatal exception occurred:</span><br></pre></td></tr></table></figure><h3 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/ambari-agent/conf/ambari-agent.ini</span><br><span class="line">在[security]下添加</span><br><span class="line">force_https_protocol=PROTOCOL_TLSv1_2</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/python/cert-verification.cfg </span><br><span class="line">在[https] 下添加</span><br><span class="line">verify=disable</span><br></pre></td></tr></table></figure><p>然后在Ambari界面点击retry进行重试操作</p>]]></content>
      
      
      <categories>
          
          <category> HDP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop问题 </tag>
            
            <tag> BigData </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS WEB UI上缺少datanode的问题解决方法</title>
      <link href="/2019/03/19/web-ui-shang-que-shao-datanode/"/>
      <url>/2019/03/19/web-ui-shang-que-shao-datanode/</url>
      
        <content type="html"><![CDATA[<h2 id="1、集群结构"><a href="#1、集群结构" class="headerlink" title="1、集群结构"></a>1、集群结构</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">192.168.0.60 host0</span><br><span class="line">192.168.0.61 host1</span><br><span class="line">192.168.0.62 host2</span><br><span class="line">192.168.0.63 host3</span><br><span class="line">192.168.0.64 host4</span><br></pre></td></tr></table></figure><h2 id="2、问题状况"><a href="#2、问题状况" class="headerlink" title="2、问题状况"></a>2、问题状况</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#HDFS上显示存活的datanode个数为4个</span></span><br><span class="line"><span class="comment">#HDFS WEB UI上显示的datanode个数为三个</span></span><br><span class="line"><span class="comment">#缺少host4节点的datanode</span></span><br></pre></td></tr></table></figure><h2 id="3、问题解决思路"><a href="#3、问题解决思路" class="headerlink" title="3、问题解决思路"></a>3、问题解决思路</h2><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">1、检查namenode与host4是否可以ping通</span><br><span class="line">2、如果不可以ping通，检查host4上的hosts文件，以及网络文件配置</span><br><span class="line">3、如果可以ping通，则检查host4当前的ip地址，有可能在免密配置完成后，重启主机，ip发生变化，此时192.168.168.0.64的地址仍然可以ping通，但是服务却不能连接，因此会导致在WEB UI上无法显示datanode，只需要修改网络配置文件，设置为静态IP即可，然后重启network。</span><br><span class="line">4、停止Hadoop所有服务，然后重启Hadoop集群，即可在WEB UI上查看到host4的datanode信息。</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> HDP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop问题 </tag>
            
            <tag> BigData </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Splice Engine历史拉链测试总结</title>
      <link href="/2019/03/19/splice-engine-li-shi-la-lian-ce-shi-zong-jie/"/>
      <url>/2019/03/19/splice-engine-li-shi-la-lian-ce-shi-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="基本环境参数"><a href="#基本环境参数" class="headerlink" title="基本环境参数"></a>基本环境参数</h2><p>Splice.olap.shuffle.partitions=1200</p><p>Dsplice.spark.yarn.executor.memoryOverhead=6144</p><p>Dsplice.spark.executor.memory=10g</p><p>splice.olap_server.external=true</p><p>splice.olap_server.memory=20480</p><p>HBASE_HEAPSIZE=20480</p><p>splice.splitBlockSize=32108864</p><h2 id="1、设置splice-olap-shuffle-partitions"><a href="#1、设置splice-olap-shuffle-partitions" class="headerlink" title="1、设置splice.olap.shuffle.partitions"></a>1、设置splice.olap.shuffle.partitions</h2><p>在 hbase的 custom hbase-site中添加splice.olap.shuffle.partitions=400，400数值可进行修改，400是一个相对稳妥的数值，该参数影响在<strong>shuffle</strong>过程中分区的个数，从而影响<strong>task</strong>的数量，如下是在测试10G数据时设置400和1200的参数运行效果：</p><p>​                                        <strong>10G结果对比</strong></p><table><thead><tr><th style="text-align:center">比较内容</th><th style="text-align:center">400</th><th style="text-align:center">1200</th></tr></thead><tbody><tr><td style="text-align:center">Split</td><td style="text-align:center"><strong>381s</strong></td><td style="text-align:center"><strong>343s</strong></td></tr><tr><td style="text-align:center">Minor compaction</td><td style="text-align:center">0s</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">Major compaction</td><td style="text-align:center">0s</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">闭链</td><td style="text-align:center"><strong>365s</strong></td><td style="text-align:center"><strong>325s</strong></td></tr><tr><td style="text-align:center">Minor compaction</td><td style="text-align:center">152s(24个)</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">Major compaction</td><td style="text-align:center">0s</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">开链</td><td style="text-align:center"><strong>105s</strong></td><td style="text-align:center"><strong>131s</strong></td></tr><tr><td style="text-align:center">Minor compaction</td><td style="text-align:center">0s</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">Major compaction</td><td style="text-align:center">0s</td><td style="text-align:center">0s</td></tr><tr><td style="text-align:center">总计</td><td style="text-align:center"><strong>851s</strong></td><td style="text-align:center"><strong>793s</strong></td></tr></tbody></table><p>​                                        <strong>10G测试结果</strong></p><table><thead><tr><th style="text-align:center">比较内容</th><th style="text-align:center">SM2.7.0.1907 partitions=400</th><th style="text-align:center">SM2.7.0.1907 partitions=600</th><th style="text-align:center">SM2.7.0.1907 partitions=1200</th></tr></thead><tbody><tr><td style="text-align:center">SPLIT</td><td style="text-align:center">123.986s</td><td style="text-align:center">109.756s</td><td style="text-align:center">109.925s</td></tr><tr><td style="text-align:center">闭链</td><td style="text-align:center">64.074s</td><td style="text-align:center">54.260s</td><td style="text-align:center">53.399s</td></tr><tr><td style="text-align:center">开链</td><td style="text-align:center">57.084s</td><td style="text-align:center">55.067s</td><td style="text-align:center">55.086s</td></tr><tr><td style="text-align:center">总计</td><td style="text-align:center">245.126s</td><td style="text-align:center">219.083s</td><td style="text-align:center">218.41s</td></tr></tbody></table><p>适量的设置该参数可以提升运行速度，但是过度设置splice.olap.shuffle.partitions参数不会减少运行时间反而会增加运行时间，所以该参数需要多次尝试修改，并且针对不同的数据量设置的大小也会不一样。</p><h2 id="2、创建表的字段类型选择问题"><a href="#2、创建表的字段类型选择问题" class="headerlink" title="2、创建表的字段类型选择问题"></a>2、创建表的字段类型选择问题</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> T_TELLER_ROLES_EXT_0214(</span><br><span class="line"><span class="keyword">ID</span><span class="built_in">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">STAFF_ID <span class="built_in">VARCHAR</span>(<span class="number">20</span>),</span><br><span class="line">ROLE_ID<span class="built_in">VARCHAR</span>(<span class="number">20</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>尽量避免使用VARCHAR() 类型，在进行字段的比较时速度较慢。</p><p><strong>目前还使用的VARCHAR()类型，下一步尝试使用数字类型。</strong></p><h2 id="3、修改splice-splitBlockSize"><a href="#3、修改splice-splitBlockSize" class="headerlink" title="3、修改splice.splitBlockSize"></a>3、修改splice.splitBlockSize</h2><p>该参数影响使用多少个task从磁盘中读取数据，默认是<strong>67108864</strong>，可设置为<strong>32108864</strong>，具体大小还需要针对不同的运行情况，建议不要修改。</p><h2 id="4、insert-语句的编写"><a href="#4、insert-语句的编写" class="headerlink" title="4、insert 语句的编写"></a>4、insert 语句的编写</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#第一种</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> T_TELLER_ROLES_ADD <span class="comment">--splice-properties bulkImportDirectory='/data/poc/HIS', useSpark=true, skipSampling=false</span></span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T_TELLER_ROLES_EXT_0215 <span class="keyword">EXCEPT</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T_TELLER_ROLES_EXT_0214;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#第二种</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> T_TELLER_ROLES_ADD <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T_TELLER_ROLES_EXT_0215 <span class="keyword">EXCEPT</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> T_TELLER_ROLES_EXT_0214;</span><br></pre></td></tr></table></figure><p>第一种是使用SM <strong>bulk load</strong>的方式向表中插入数据，参数bulkImportDirectory指的是SM有读写权限的文件夹，用于保存运行日志，其余参数可在官方文档中有详细解释。</p><h2 id="5、Error-resin-resin-U"><a href="#5、Error-resin-resin-U" class="headerlink" title="5、Error resin resin.U"></a>5、Error resin resin.U</h2><p>这个问题指的是资源使用已满，需要重启HBase，这个目前算是个<strong>BUG</strong>，在<strong>1905</strong>版本以后修复了。</p><h2 id="6、查询不到表的BUG"><a href="#6、查询不到表的BUG" class="headerlink" title="6、查询不到表的BUG"></a>6、查询不到表的BUG</h2><p>在创建表后，使用 show tables 无法查询到表的信息，但是可以对表进行操作，这个问题是系统缓存的问题，重启shell客户端，重新进行创建表即可。</p><h2 id="7、官网参数的修改"><a href="#7、官网参数的修改" class="headerlink" title="7、官网参数的修改"></a>7、官网参数的修改</h2><p><strong>官网参数为：</strong></p><table><thead><tr><th style="text-align:center">参数名称</th><th style="text-align:center">数值</th></tr></thead><tbody><tr><td style="text-align:center">hbase.hstore.defaultengine.compactor</td><td style="text-align:center">com.splicemachine.compactions.SpliceDefaultCompactor</td></tr><tr><td style="text-align:center">hbase.hstore.defaultengine.compactionpolicy</td><td style="text-align:center">com.splicemachine.compactions.SpliceDefaultCompactionPolicy</td></tr></tbody></table><p><strong>修改后：</strong></p><table><thead><tr><th style="text-align:center">参数名称</th><th style="text-align:center">数值</th></tr></thead><tbody><tr><td style="text-align:center">hbase.hstore.defaultengine.compactor<strong>.class</strong></td><td style="text-align:center">com.splicemachine.compactions.SpliceDefaultCompactor</td></tr><tr><td style="text-align:center">hbase.hstore.defaultengine.compactionpolicy<strong>.class</strong></td><td style="text-align:center">com.splicemachine.compactions.SpliceDefaultCompactionPolicy</td></tr></tbody></table><h2 id="8、如下参数谨慎设置"><a href="#8、如下参数谨慎设置" class="headerlink" title="8、如下参数谨慎设置"></a>8、如下参数谨慎设置</h2><p>hbase.hstore.compaction.max.size设置为Long.MAX_VALUE，设置完之后SM服务会无法启动，所以该参数<strong>不要修改</strong>变动。</p><h2 id="9、HBase自身的问题"><a href="#9、HBase自身的问题" class="headerlink" title="9、HBase自身的问题"></a>9、HBase自身的问题</h2><p><strong>错误一：</strong>So there may be a TCP socket connection left open in CLOSE_WAIT state. For more details check <a href="https://issues.apache.org/jira/browse/HBASE-9393" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/HBASE-9393</a><br>后面的URL指向这个问题的解决方式</p><h2 id="10、Hmaster与regionserver"><a href="#10、Hmaster与regionserver" class="headerlink" title="10、Hmaster与regionserver"></a>10、Hmaster与regionserver</h2><p>配置集群时，Hmaster与regionserver服务不要放在同一节点上，splice服务要与regionserver放在同一节点上。</p><h2 id="11、删除表后，在hbase中不会删除，而是会在原来表的位置打标记。"><a href="#11、删除表后，在hbase中不会删除，而是会在原来表的位置打标记。" class="headerlink" title="11、删除表后，在hbase中不会删除，而是会在原来表的位置打标记。"></a>11、删除表后，在hbase中不会删除，而是会在原来表的位置打标记。</h2><p>运行CALL SYSCS_UTIL.VACUUM();删除已经被删除的表</p><p>详细介绍：<a href="https://doc.splicemachine.com/sqlref_sysprocs_vacuum.html" target="_blank" rel="noopener">https://doc.splicemachine.com/sqlref_sysprocs_vacuum.html</a></p><p>在删除一张表并且重新创建一张与原来相同表名的表需要在创建表之前执行该命令。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Drop</span> <span class="keyword">table</span> A;</span><br><span class="line"><span class="keyword">CALL</span> SYSCS_UTIL.VACUUM();</span><br><span class="line"><span class="keyword">Create</span> <span class="keyword">table</span> A;</span><br></pre></td></tr></table></figure><h2 id="12、增加spark的执行内存"><a href="#12、增加spark的执行内存" class="headerlink" title="12、增加spark的执行内存"></a>12、增加spark的执行内存</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Job aborted due to stage failure: Task 15 in stage 181.0 failed 4 times, most recent failure: Lost task 15.3 in stage 181.0 (TID 3633, master, executor 361): ExecutorLostFailure (executor 361 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 14.3 GB of 14 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.</span><br><span class="line">Driver stacktrace:</span><br></pre></td></tr></table></figure><p>当出现以上问题时，需要修改如下参数：</p><p>Dsplice.spark.yarn.executor.memoryOverhead=6144</p><p>Dsplice.spark.executor.memory=10g。</p><h2 id="13、修改HBASE-HEAPSIZE"><a href="#13、修改HBASE-HEAPSIZE" class="headerlink" title="13、修改HBASE_HEAPSIZE"></a>13、修改HBASE_HEAPSIZE</h2><p>官网建议将splice.olap_server.memory的大小设置和HMaster heap size的大小相同。</p><h2 id="14、其他优化参数"><a href="#14、其他优化参数" class="headerlink" title="14、其他优化参数"></a>14、其他优化参数</h2><h2 id="15、向Splice导入数据时注意事项"><a href="#15、向Splice导入数据时注意事项" class="headerlink" title="15、向Splice导入数据时注意事项"></a>15、向Splice导入数据时注意事项</h2><p>例：<strong>在所有导入数据的方法中</strong></p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">call</span> SYSCS_UTIL.BULK_IMPORT_HFILE (</span><br><span class="line">    schemaName,</span><br><span class="line">    tableName,</span><br><span class="line">    insertColumnList | <span class="literal">null</span>,</span><br><span class="line">    fileName,</span><br><span class="line">    columnDelimiter | <span class="literal">null</span>,</span><br><span class="line">    characterDelimiter | <span class="literal">null</span>,</span><br><span class="line">    timestampFormat | <span class="literal">null</span>,</span><br><span class="line">    dateFormat | <span class="literal">null</span>,</span><br><span class="line">    timeFormat | <span class="literal">null</span>,</span><br><span class="line">    maxBadRecords,</span><br><span class="line">    badRecordDirectory | <span class="literal">null</span>,</span><br><span class="line">    oneLineRecords | <span class="literal">null</span>,</span><br><span class="line">    <span class="keyword">charset</span> | <span class="literal">null</span>,</span><br><span class="line">    bulkImportDirectory,</span><br><span class="line">    skipSampling</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p><strong>bulkImportDirectory</strong>一定要将数据放在<strong>除一级目录</strong>之外的次级目录中，如/data/14g.csv或/data/poc/14g.csv等</p><p>在使用<strong>BULK_IMPORT_HFILE</strong>方法时需要修改如下参数：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yarn.nodemanager.pmem-check-enabled=false</span><br><span class="line">yarn.nodemanager.vmem-check-enabled=false</span><br></pre></td></tr></table></figure><h2 id="16、磁盘管理"><a href="#16、磁盘管理" class="headerlink" title="16、磁盘管理"></a>16、磁盘管理</h2><p>当磁盘空间到达阀值时，yarn会拒绝启动，默认阀值为90%，建议不要修改。</p><h2 id="17、Splice其他参数"><a href="#17、Splice其他参数" class="headerlink" title="17、Splice其他参数"></a>17、Splice其他参数</h2><h2 id="18、查询优化"><a href="#18、查询优化" class="headerlink" title="18、查询优化"></a>18、查询优化</h2><h2 id="19、导入数据报错"><a href="#19、导入数据报错" class="headerlink" title="19、导入数据报错"></a>19、导入数据报错</h2><p>1⃣️</p><p>一、连接超时</p><p>报错日志如下：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2019-05-15 13:11:35,679 ERROR [shuffle-client-6-3] server.TransportChannelHandler: Connection to host4/192.168.0.64:7447 has been quiet <span class="keyword">for</span> 120000 ms <span class="keyword">while</span> there are outstanding requests. Assuming connection is dead; please adjust spark.network.timeout <span class="keyword">if</span> this is wrong.</span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在hbase-env中添加</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MASTER_OPTS=<span class="string">"<span class="variable">$&#123;HBASE_MASTER_OPTS&#125;</span>-Dsplice.spark.shuffle.io.connectionTimeout=480s"</span></span><br><span class="line"><span class="comment">#注意双引号</span></span><br></pre></td></tr></table></figure><p>二、无法完成批量加载数据</p><p>导入数据命令：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">call SYSCS_UTIL.BULK_IMPORT_HFILE(<span class="string">'TPCH'</span>, <span class="string">'ORDERS'</span>, null,<span class="string">'/TPCH/1/orders'</span>, <span class="string">'|'</span>, null, null, null, null, 0,<span class="string">'/TPCH/log/'</span>, <span class="literal">true</span>, null, <span class="string">'/tmp'</span>, <span class="literal">false</span>);</span><br></pre></td></tr></table></figure><p>报错日志如下：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">2019-05-16 17:27:50,481 ERROR [RpcServer.FifoWFPBQ.default.handler=198,queue=18,port=16020] access.SecureBulkLoadEndpoint: Failed to complete bulk load</span><br><span class="line">java.lang.IllegalArgumentException: Wrong FS: hdfs://SM/tmp/5152/650bbcaa243d4b47bc2c1a72973b8599/V/5de6a76d4cb74c3ab50d683166435b4e, expected: hdfs://host0:8020</span><br><span class="line"></span><br><span class="line"><span class="comment">#当前hdfs的core-site中，fs.defaultFS=SM，所以会报错，期望值为 hdfs://host0:8020</span></span><br></pre></td></tr></table></figure><p>解决方法：</p><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment">#1、将导入数据命令修改为如下</span></span><br><span class="line">call SYSCS_UTIL.BULK_IMPORT_HFILE(<span class="string">'TPCH'</span>, <span class="string">'ORDERS'</span>, null,<span class="string">'/TPCH/1/orders'</span>, <span class="string">'|'</span>, null, null, null, null, 0,<span class="string">'/TPCH/log/'</span>, <span class="literal">true</span>, null, <span class="string">'hdfs://host0:8020/tmp'</span>, <span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">#2、如果导入数据成功则按照一下步骤进行</span></span><br><span class="line"><span class="comment">#修改hdfs的core-site中fs.defaultFS=hdfs://host0:8020，然后重启服务</span></span><br><span class="line">fs.defaultFS=hdfs://host0:8020</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Splice Engine </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Splice Engine优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Yarn Register DNS 端口占用</title>
      <link href="/2019/01/29/yarn-register-dns/"/>
      <url>/2019/01/29/yarn-register-dns/</url>
      
        <content type="html"><![CDATA[<p>如果在安装时看到与YARN Registry DNS Bind Port相关的错误。可以参考以下步骤操作：</p><h2 id="1、打开Ambari管理界面并进入YARN管理界面"><a href="#1、打开Ambari管理界面并进入YARN管理界面" class="headerlink" title="1、打开Ambari管理界面并进入YARN管理界面"></a>1、打开Ambari管理界面并进入YARN管理界面</h2><p><img src="/images/Yarn_Register_DNS/1.png" alt=""></p><h2 id="2、点击CONFIGS，进入配置界面"><a href="#2、点击CONFIGS，进入配置界面" class="headerlink" title="2、点击CONFIGS，进入配置界面"></a>2、点击CONFIGS，进入配置界面</h2><p><img src="/images/Yarn_Register_DNS/2.png" alt=""></p><h2 id="3、点击ADVANCED进入高级设置中修改DNS端口号"><a href="#3、点击ADVANCED进入高级设置中修改DNS端口号" class="headerlink" title="3、点击ADVANCED进入高级设置中修改DNS端口号"></a>3、点击ADVANCED进入高级设置中修改DNS端口号</h2><p><img src="/images/Yarn_Register_DNS/3.png" alt=""></p><p><strong>将53修改成其他不被占用的端口即可</strong></p><h2 id="4、重启集群，YARN正常启动"><a href="#4、重启集群，YARN正常启动" class="headerlink" title="4、重启集群，YARN正常启动"></a>4、重启集群，YARN正常启动</h2><p><img src="/images/Yarn_Register_DNS/4.png" alt=""></p><p>参考文献：<a href="https://community.hortonworks.com/articles/225841/yarn-registry-dns-port-conflict-issue.html" target="_blank" rel="noopener">Hortonworks</a></p>]]></content>
      
      
      <categories>
          
          <category> HDP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop问题 </tag>
            
            <tag> BigData </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDP安装——基础环境配置</title>
      <link href="/2019/01/29/hdp-an-zhuang-ji-chu-pei-zhi/"/>
      <url>/2019/01/29/hdp-an-zhuang-ji-chu-pei-zhi/</url>
      
        <content type="html"><![CDATA[<h2 id="一、下载安装包"><a href="#一、下载安装包" class="headerlink" title="一、下载安装包"></a>一、下载安装包</h2><p><strong>注：安装centos7时，安装英文版，避免环境安装时报错</strong></p><table><thead><tr><th style="text-align:left"><strong>ambari</strong></th><th><strong><a href="http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.3.0/ambari-2.7.3.0-centos7.tar.gz" target="_blank" rel="noopener">http://public-repo-1.hortonworks.com/ambari/centos7/2.x/updates/2.7.3.0/ambari-2.7.3.0-centos7.tar.gz</a></strong></th></tr></thead><tbody><tr><td style="text-align:left"><strong>HDP</strong></td><td><strong><a href="http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.0.0/HDP-3.1.0.0-centos7-rpm.tar.gz" target="_blank" rel="noopener">http://public-repo-1.hortonworks.com/HDP/centos7/3.x/updates/3.1.0.0/HDP-3.1.0.0-centos7-rpm.tar.gz</a></strong></td></tr><tr><td style="text-align:left"><strong>HDP-UTILS</strong></td><td><strong><a href="http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gz" target="_blank" rel="noopener">http://public-repo-1.hortonworks.com/HDP-UTILS-1.1.0.22/repos/centos7/HDP-UTILS-1.1.0.22-centos7.tar.gz</a></strong></td></tr><tr><td style="text-align:left"><strong>HDP-GPL</strong></td><td><strong><a href="http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.0.0/HDP-GPL-3.1.0.0-centos7-gpl.tar.gz" target="_blank" rel="noopener">http://public-repo-1.hortonworks.com/HDP-GPL/centos7/3.x/updates/3.1.0.0/HDP-GPL-3.1.0.0-centos7-gpl.tar.gz</a></strong></td></tr></tbody></table><hr><h2 id="二、系统环境配置"><a href="#二、系统环境配置" class="headerlink" title="二、系统环境配置"></a>二、系统环境配置</h2><p><strong>所有操作都是root用户</strong></p><h3 id="1、修改主机名"><a href="#1、修改主机名" class="headerlink" title="1、修改主机名"></a>1、修改主机名</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">master01 #主机名称</span><br></pre></td></tr></table></figure><h3 id="2、修改网络"><a href="#2、修改网络" class="headerlink" title="2、修改网络"></a>2、修改网络</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-enp0s31f6 #ifcfg-enp0s31f6 为网卡名称</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">BOOTPROTO="static"          # 使用静态IP地址，默认为dhcp</span><br><span class="line">IPADDR="192.168.0.80"   # 设置的静态IP地址</span><br><span class="line">NETMASK="255.255.255.0"     # 子网掩码</span><br><span class="line">GATEWAY="192.168.0.1"       # 网关地址</span><br><span class="line">DNS1="8.8.8.8"           # DNS服务器</span><br><span class="line">ONBOOT="yes"             #是否开机启用</span><br></pre></td></tr></table></figure><h3 id="3、配置hosts文件"><a href="#3、配置hosts文件" class="headerlink" title="3、配置hosts文件"></a>3、配置hosts文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line"></span><br><span class="line">192.168.0.80 master01</span><br><span class="line">192.168.0.81 node01</span><br><span class="line">192.168.0.82 node02</span><br></pre></td></tr></table></figure><h3 id="4、关闭防火墙"><a href="#4、关闭防火墙" class="headerlink" title="4、关闭防火墙"></a>4、关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure><h3 id="5、设置SSH免密登陆"><a href="#5、设置SSH免密登陆" class="headerlink" title="5、设置SSH免密登陆"></a>5、设置SSH免密登陆</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">ssh-keygen </span><br><span class="line">三下回车</span><br><span class="line">ssh-copy-id master01</span><br><span class="line">ssh-copy-id node01</span><br><span class="line">ssh-copy-id node02</span><br></pre></td></tr></table></figure><h3 id="6、检查DNS和NSCD"><a href="#6、检查DNS和NSCD" class="headerlink" title="6、检查DNS和NSCD"></a>6、检查DNS和NSCD</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">setenforce 0#临时设置 重启失效</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">vim /etc/selinux/config#永久有效 需重启机器</span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">umask 0022#临时设置 重启失效</span><br><span class="line">echo umask 0022 &gt;&gt; /etc/profile#永久有效 重启生效</span><br><span class="line">umask #检查当前机器的umask码</span><br></pre></td></tr></table></figure><h3 id="7、修改文件打开限制"><a href="#7、修改文件打开限制" class="headerlink" title="7、修改文件打开限制"></a>7、修改文件打开限制</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">vim /etc/security/limits.conf</span><br><span class="line"><span class="meta">#</span><span class="bash">在文件最后</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> End of file</span></span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br><span class="line">* soft nproc 131072</span><br><span class="line">* hard nproc 131072</span><br></pre></td></tr></table></figure><h3 id="8、同步时钟"><a href="#8、同步时钟" class="headerlink" title="8、同步时钟"></a>8、同步时钟</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">ln -s /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">yum -y install ntp</span><br><span class="line"><span class="meta">#</span><span class="bash">在主服务器上</span></span><br><span class="line">vim /etc/ntp.conf</span><br><span class="line"><span class="meta">#</span><span class="bash">在文件中配置</span></span><br><span class="line">restrict default nomodify notrap nopeer noquery</span><br><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br><span class="line"><span class="meta">#</span><span class="bash">在子节点中</span></span><br><span class="line">crontab -e</span><br><span class="line">0-59/10 * * * * /usr/sbin/ntpdate master01</span><br><span class="line"><span class="meta">#</span><span class="bash">在所有节点启动服务</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line">systemctl enable ntpd</span><br></pre></td></tr></table></figure><h3 id="9、安装JDK"><a href="#9、安装JDK" class="headerlink" title="9、安装JDK"></a>9、安装JDK</h3><h4 id="Ⅰ、先安装openjdk"><a href="#Ⅰ、先安装openjdk" class="headerlink" title="Ⅰ、先安装openjdk"></a>Ⅰ、<strong>先安装openjdk</strong></h4><p>​            安装openjdk解决包依赖的问题</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">yum -y install java</span><br></pre></td></tr></table></figure><h4 id="Ⅱ、卸载openjdk"><a href="#Ⅱ、卸载openjdk" class="headerlink" title="Ⅱ、卸载openjdk"></a>Ⅱ、卸载openjdk</h4><p>​        卸载jdk包，但是保留依赖包</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line">rpm -qa|grep java</span><br><span class="line">yum remove java-1.8.0-openjdk-1.8.0.161-0.b14.el7_4.x86_64</span><br></pre></td></tr></table></figure><h4 id="Ⅲ、安装开源JDK"><a href="#Ⅲ、安装开源JDK" class="headerlink" title="Ⅲ、安装开源JDK"></a>Ⅲ、安装开源JDK</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上</span></span><br><span class="line"><span class="meta">#</span><span class="bash">下载jdk</span></span><br><span class="line">wget https://download.oracle.com/otn-pub/java/jdk/8u201-b09/42970487e3af4f5aa5bca3f542482c60/jdk-8u201-linux-x64.rpm?AuthParam=1548732196_c3d078fb7f78308027532d04a26b4612</span><br><span class="line"><span class="meta">#</span><span class="bash">重命名</span></span><br><span class="line">mv jdk-8u201-linux-x64.rpm?AuthParam=1548732196_c3d078fb7f78308027532d04a26b4612 jdk-8u201-linux-x64.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash">安装jdk</span></span><br><span class="line">rpm -ivh jdk-8u201-linux-x64.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash">检查jdk版本</span></span><br><span class="line">java -version</span><br><span class="line"></span><br><span class="line">java version "1.8.0_201"</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_201-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)</span><br><span class="line"><span class="meta">#</span><span class="bash">修改配置文件</span></span><br><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_201-amd64</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar </span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><h3 id="10、安装MySQL"><a href="#10、安装MySQL" class="headerlink" title="10、安装MySQL"></a>10、安装MySQL</h3><p><strong>默认是PostgreSQL，但是在生产环境中不建议使用，所以安装mysql或其他，mysql安装在主节点上，如有需要可以安装在其他节点上</strong></p><h4 id="Ⅰ、卸载原来的MySQL"><a href="#Ⅰ、卸载原来的MySQL" class="headerlink" title="Ⅰ、卸载原来的MySQL"></a>Ⅰ、卸载原来的MySQL</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -qa|grep -i mysql #查看是否安装mysql</span><br><span class="line">yum remove … #卸载mysql所有内容</span><br><span class="line">find / -name mysql#查找mysql所有文件位置</span><br><span class="line">rm -rf /var/lib/mysql…#删除mysql相关文件</span><br><span class="line">rm -rf /var/log/mysql.log #删除该日志文件</span><br></pre></td></tr></table></figure><h4 id="Ⅱ、下载安装MySQL5-6"><a href="#Ⅱ、下载安装MySQL5-6" class="headerlink" title="Ⅱ、下载安装MySQL5.6"></a>Ⅱ、下载安装MySQL5.6</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">yum install mysql-server#安装mysql</span><br><span class="line">systemctl start mysqld#启动mysql</span><br><span class="line">systemctl enable mysqld#开机启动</span><br></pre></td></tr></table></figure><h4 id="Ⅲ、修改默认密码"><a href="#Ⅲ、修改默认密码" class="headerlink" title="Ⅲ、修改默认密码"></a>Ⅲ、修改默认密码</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p (无密码)</span><br><span class="line">use mysql</span><br><span class="line">select host,user,password from user;</span><br><span class="line">delete from user where user='';</span><br><span class="line">update user set host='%' where user='localhost';#(如果无user=localhost 可不执行这条命令)</span><br><span class="line">update user set password=PASSWORD('123456') where host='%'#(这条命令是根据上条执行)</span><br><span class="line">update user set password=PASSWORD('123456') where user='root' and host='localhost';</span><br><span class="line">update user set password=PASSWORD('123456') where user='root' and host='master';#(可选操作，master01为主机名)</span><br><span class="line">grant all privileges on *.* to 'root'@'%' identified by '123456' with grant option;#(远程连接数据库权限设置)</span><br><span class="line">flush privileges; #要刷新权限</span><br></pre></td></tr></table></figure><h2 id="三、修改yum源，实现离线安装"><a href="#三、修改yum源，实现离线安装" class="headerlink" title="三、修改yum源，实现离线安装"></a>三、修改yum源，实现离线安装</h2><h3 id="1、安装httpd"><a href="#1、安装httpd" class="headerlink" title="1、安装httpd"></a>1、安装httpd</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line">yum -y install httpd</span><br><span class="line">service httpd restart</span><br><span class="line">systemctl enable httpd</span><br></pre></td></tr></table></figure><h3 id="2、修改安装文件位置"><a href="#2、修改安装文件位置" class="headerlink" title="2、修改安装文件位置"></a>2、修改安装文件位置</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line">cd /var/www/html/</span><br><span class="line">mkdir ambari</span><br><span class="line"><span class="meta">#</span><span class="bash">解压文件</span></span><br><span class="line">tar -xvzf ambari-2.7.3.0-centos7.tar.gz</span><br><span class="line">tar -xvzf HDP-3.1.0.0-centos7-rpm.tar.gz</span><br><span class="line">tar -xvzf HDP-GPL-3.1.0.0-centos7-gpl.tar.gz</span><br><span class="line">tar -xvzf HDP-UTILS-1.1.0.22-centos7.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash">打开http://192.168.0.80/ambari 查看是否有结果</span></span><br></pre></td></tr></table></figure><h3 id="3、制作本地源"><a href="#3、制作本地源" class="headerlink" title="3、制作本地源"></a>3、制作本地源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash">在/var/www/html/ambari目录下创建yum源</span></span><br><span class="line">yum install yum-utils createrepo yum-plugin-priorities -y</span><br><span class="line">createrepo  ./</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash">修改ambari安装包源配置</span></span><br><span class="line">cd /var/www/html/ambari/ambari/centos7/2.7.3.0-139</span><br><span class="line">vim ambari.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">VERSION_NUMBER=2.7.3.0-139</span></span><br><span class="line">[ambari-2.7.3.0]</span><br><span class="line"><span class="meta">#</span><span class="bash">json.url = http://public-repo-1.hortonworks.com/HDP/hdp_urlinfo.json</span></span><br><span class="line">name=ambari Version - ambari-2.7.3.0</span><br><span class="line">baseurl=http://192.168.0.80/ambari/ambari/centos7/2.7.3.0-139</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.0.80/ambari/ambari/centos7/2.7.3.0-139/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line"><span class="meta">#</span><span class="bash">修改HDP配置文件</span></span><br><span class="line">cd /var/www/html/ambari/HDP/centos7/3.1.0.0-78</span><br><span class="line">vim hdp.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">VERSION_NUMBER=3.1.0.0-78</span></span><br><span class="line">[HDP-3.1.0.0]</span><br><span class="line">name=HDP Version - HDP-3.1.0.0</span><br><span class="line">baseurl=http://192.168.0.80/ambari/HDP/centos7/3.1.0.0-78</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.0.80/ambari/HDP/centos7/3.1.0.0-78/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br><span class="line"></span><br><span class="line">[HDP-UTILS-1.1.0.22]</span><br><span class="line">name=HDP-UTILS Version - HDP-UTILS-1.1.0.22</span><br><span class="line">baseurl=http://192.168.0.80/ambari/HDP-UTILS/centos7/1.1.0.22</span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://192.168.0.80/ambari/HDP-UTILS/centos7/1.1.0.22/RPM-GPG-KEY/RPM-GPG-KEY-Jenkins</span><br><span class="line">enabled=1</span><br><span class="line">priority=1</span><br></pre></td></tr></table></figure><h3 id="4、将repo文件辅助到YUM库"><a href="#4、将repo文件辅助到YUM库" class="headerlink" title="4、将repo文件辅助到YUM库"></a>4、将repo文件辅助到YUM库</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line">cp /var/www/html/ambari/ambari/centos7/2.7.3.0-139/ambari.repo /etc/yum.repos.d/</span><br><span class="line">cp /var/www/html/ambari/HDP/centos7/3.1.0.0-78/hdp.repo /etc/yum.repos.d/</span><br></pre></td></tr></table></figure><h3 id="5、将文件拷贝到子节点"><a href="#5、将文件拷贝到子节点" class="headerlink" title="5、将文件拷贝到子节点"></a>5、将文件拷贝到子节点</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在master01上执行</span></span><br><span class="line">scp /etc/yum.repos.d/ambari.repo node01:/etc/yum.repos.d/</span><br><span class="line">scp /etc/yum.repos.d/ambari.repo node02:/etc/yum.repos.d/</span><br><span class="line">scp /etc/yum.repos.d/hdp.repo node01:/etc/yum.repos.d/</span><br><span class="line">scp /etc/yum.repos.d/hdp.repo node02:/etc/yum.repos.d/</span><br></pre></td></tr></table></figure><h3 id="6、重新设置YUM缓存"><a href="#6、重新设置YUM缓存" class="headerlink" title="6、重新设置YUM缓存"></a>6、重新设置YUM缓存</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在所有机器上执行</span></span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure><h2 id="四、安装ambari-server"><a href="#四、安装ambari-server" class="headerlink" title="四、安装ambari-server"></a>四、安装ambari-server</h2><h3 id="1、在MySQL中创建用户和数据库"><a href="#1、在MySQL中创建用户和数据库" class="headerlink" title="1、在MySQL中创建用户和数据库"></a>1、在MySQL中创建用户和数据库</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">根据安装软件需要自己选择要创建的数据库和用户</span></span><br><span class="line">CREATE DATABASE ambari;  </span><br><span class="line">use ambari;  </span><br><span class="line">CREATE USER 'ambari'@'%' IDENTIFIED BY '123456';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'%';  </span><br><span class="line">CREATE USER 'ambari'@'localhost' IDENTIFIED BY '123456';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'localhost';  </span><br><span class="line">CREATE USER 'ambari'@'master01' IDENTIFIED BY '123456';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'ambari'@'master01';  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line"></span><br><span class="line">CREATE DATABASE hive;  </span><br><span class="line">use hive;  </span><br><span class="line">CREATE USER 'hive'@'%' IDENTIFIED BY 'hive';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'hive'@'%';  </span><br><span class="line">CREATE USER 'hive'@'localhost' IDENTIFIED BY 'hive';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'hive'@'localhost';  </span><br><span class="line">CREATE USER 'hive'@'master01' IDENTIFIED BY 'hive';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'hive'@'master01';  </span><br><span class="line">FLUSH PRIVILEGES;  </span><br><span class="line"></span><br><span class="line">CREATE DATABASE oozie;  </span><br><span class="line">use oozie;  </span><br><span class="line">CREATE USER 'oozie'@'%' IDENTIFIED BY 'oozie';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'%';  </span><br><span class="line">CREATE USER 'oozie'@'localhost' IDENTIFIED BY 'oozie';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'localhost';  </span><br><span class="line">CREATE USER 'oozie'@'master01' IDENTIFIED BY 'oozie';  </span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO 'oozie'@'master01';  </span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure><h3 id="2、将jar包放入环境"><a href="#2、将jar包放入环境" class="headerlink" title="2、将jar包放入环境"></a>2、将jar包放入环境</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">下载mysql-connector-java-5.1.47.tar.gz</span></span><br><span class="line">cd /data</span><br><span class="line">wget https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.47.tar.gz</span><br><span class="line">tar -xvzf mysql-connector-java-5.1.47.tar.gz</span><br><span class="line">cp /data/mysql-connector-java-5.1.47/mysql-connector-java-5.1.47* /usr/share/java/</span><br><span class="line">cd /usr/share/java/</span><br><span class="line">mv mysql-connector-java-5.1.47.jar mysql-connector-java.jar</span><br><span class="line">cp /usr/share/java/mysql-connector-java.jar /var/lib/ambari-server/resources/mysql-jdbc-driver.jar</span><br></pre></td></tr></table></figure><h3 id="3、初始化ambari-server并启动"><a href="#3、初始化ambari-server并启动" class="headerlink" title="3、初始化ambari-server并启动"></a>3、初始化ambari-server并启动</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">初始化</span></span><br><span class="line">ambari-server setup --jdbc-db=mysql --jdbc-driver=/usr/share/java/mysql-connector-java.jar</span><br><span class="line"><span class="meta">#</span><span class="bash">配置ambari</span></span><br><span class="line">ambari-server setup</span><br><span class="line"><span class="meta">#</span><span class="bash">所有选项选择y即可，当遇到如下选项时</span></span><br><span class="line"><span class="meta">#</span><span class="bash">配置JDK环境</span></span><br><span class="line">Checking JDK...</span><br><span class="line">Do you want to change Oracle JDK [y/n] (n)? y</span><br><span class="line">[1] Oracle JDK 1.8 + Java Cryptography Extension (JCE) Policy Files 8</span><br><span class="line">[2] Oracle JDK 1.7 + Java Cryptography Extension (JCE) Policy Files 7</span><br><span class="line">[3] Custom JDK</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (1): 3</span><br><span class="line">如果上面选择3自定义JDK,则需要设置JAVA_HOME。输入：/usr/java/jdk1.8.0_201-amd64</span><br><span class="line"><span class="meta">#</span><span class="bash">配置数据库</span></span><br><span class="line">Configuring database...</span><br><span class="line">Enter advanced database configuration [y/n] (n)? y</span><br><span class="line">Configuring database...</span><br><span class="line">==============================================================================</span><br><span class="line">Choose one of the following options:</span><br><span class="line">[1] - PostgreSQL (Embedded)</span><br><span class="line">[2] - Oracle</span><br><span class="line">[3] - MySQL</span><br><span class="line">[4] - PostgreSQL</span><br><span class="line">[5] - Microsoft SQL Server (Tech Preview)</span><br><span class="line">[6] - SQL Anywhere</span><br><span class="line">==============================================================================</span><br><span class="line">Enter choice (3): 3</span><br><span class="line"><span class="meta">#</span><span class="bash">设置数据库的具体配置信息，根据实际情况输入，如果和括号内相同，则可以直接回车。如果想重命名，就输入。</span></span><br><span class="line">Hostname (localhost):</span><br><span class="line">Port (3306):</span><br><span class="line">Database name (ambari):</span><br><span class="line">Username (ambari):</span><br><span class="line">Enter Database Password (bigdata):123456#创建用户时设置的密码</span><br><span class="line">Re-Enter password: 123456</span><br></pre></td></tr></table></figure><p>检查mysql中是否有新建的表</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root -p 123456</span><br><span class="line">use ambari;</span><br><span class="line">show tables;</span><br><span class="line"><span class="meta">#</span><span class="bash">如果表为空的话</span></span><br><span class="line">cd /var/lib/ambari-server/resources#sql脚本位置</span><br><span class="line">myslq -u ambari -p 123456</span><br><span class="line">use ambari;</span><br><span class="line">source Ambari-DDL-MySQL-CREATE.sql;</span><br></pre></td></tr></table></figure><h3 id="4、错误处理"><a href="#4、错误处理" class="headerlink" title="4、错误处理"></a>4、错误处理</h3><p>如果出现错误，查看server日志，根据报错进行修改</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat var/log/ambari-server/ambari-server.log</span><br></pre></td></tr></table></figure><p>也可以删除数据库重新配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ambari-server stop</span><br><span class="line">mysql -u root -p 123456</span><br><span class="line">drop database ambari;</span><br><span class="line">drop database hive;</span><br><span class="line">drop database oozie;</span><br><span class="line"><span class="meta">#</span><span class="bash">重新创建数据库</span></span><br></pre></td></tr></table></figure><h3 id="5、清除已经安装的包"><a href="#5、清除已经安装的包" class="headerlink" title="5、清除已经安装的包"></a>5、清除已经安装的包</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在ambari-server启动的状态下执行命令，清除已经安装的软件包</span></span><br><span class="line">python /usr/lib/python2.6/site-packages/ambari_agent/HostCleanup.py --silent</span><br></pre></td></tr></table></figure><h3 id="6、安装向导本地源库地址"><a href="#6、安装向导本地源库地址" class="headerlink" title="6、安装向导本地源库地址"></a>6、安装向导本地源库地址</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HDP</span></span><br><span class="line">http://192.168.0.80/ambari/HDP/centos7/3.1.0.0-78/</span><br><span class="line"><span class="meta">#</span><span class="bash">HDP-UTILS</span></span><br><span class="line">http://192.168.0.80/ambari/HDP-UTILS/centos7/1.1.0.22/</span><br><span class="line"><span class="meta">#</span><span class="bash">HDP-GPL</span></span><br><span class="line">http://192.168.0.80/ambari/HDP-GPL/centos7/3.1.0.0-78/</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> HDP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BigData </tag>
            
            <tag> HDP安装 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
